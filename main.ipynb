{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "from utils import preprocess, features, classifier, metrics, logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "models_path = 'models'\n",
    "data_path = 'data'\n",
    "model1_file_name = 'final_model1.pkl'\n",
    "model2_file_name = 'final_model2.pkl'\n",
    "comp1_pred_file_name = f'comp_m1_321128258.wtag'\n",
    "comp2_pred_file_name = f'comp_m2_321128258.wtag'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets():\n",
    "    train1_dataset = preprocess.Dataset(os.path.join(data_path, 'train1.wtag'))\n",
    "    test1_dataset = preprocess.Dataset(os.path.join(data_path, 'test1.wtag'))\n",
    "    comp1_dataset = preprocess.Dataset(os.path.join(data_path, 'comp1.words'), labeled=False, tags=train1_dataset.tags)\n",
    "\n",
    "    train2_dataset = preprocess.Dataset(os.path.join(data_path, 'train2.wtag'))\n",
    "    comp2_dataset = preprocess.Dataset(os.path.join(data_path, 'comp2.words'), labeled=False, tags=train2_dataset.tags)\n",
    "    \n",
    "    return train1_dataset, test1_dataset, comp1_dataset, train2_dataset, comp2_dataset\n",
    "\n",
    "def load_feature_vectors(train1_dataset, train2_dataset):\n",
    "    group_thresholds = {\n",
    "        # -------------------------------- feature --------------------- | -- Threshold --\n",
    "        lambda t2, t1, w, i, t: tuple([w[i].lower(), t]):                         0,     # mandatory feature f100\n",
    "        lambda t2, t1, w, i, t: tuple([w[i][-4:].lower(), t]):                    5,     # mandatory feature f101\n",
    "        lambda t2, t1, w, i, t: tuple([w[i][-3:].lower(), t]):                    5,     # mandatory feature f101\n",
    "        lambda t2, t1, w, i, t: tuple([w[i][-2:].lower(), t]):                    5,     # mandatory feature f101\n",
    "        lambda t2, t1, w, i, t: tuple([w[i][-1:].lower(), t]):                    5,     # mandatory feature f101\n",
    "        lambda t2, t1, w, i, t: tuple([w[i][:4].lower(), t]):                     5,     # mandatory feature f102\n",
    "        lambda t2, t1, w, i, t: tuple([w[i][:3].lower(), t]):                     5,     # mandatory feature f102\n",
    "        lambda t2, t1, w, i, t: tuple([w[i][:2].lower(), t]):                     5,     # mandatory feature f102\n",
    "        lambda t2, t1, w, i, t: tuple([w[i][:1].lower(), t]):                     5,     # mandatory feature f102\n",
    "        lambda t2, t1, w, i, t: tuple([t2, t1, t]):                               1,     # mandatory feature f103\n",
    "        lambda t2, t1, w, i, t: tuple([t1, t]):                                   1,     # mandatory feature f104\n",
    "        lambda t2, t1, w, i, t: tuple([t]):                                       1,     # mandatory feature f105\n",
    "        lambda t2, t1, w, i, t: tuple([w[i].islower(), t]):                       1,     # mandatory feature has_uppercase\n",
    "        lambda t2, t1, w, i, t: tuple([any(char.isdigit() for char in w[i]), t]): 1,     # mandatory feature has_digits\n",
    "        lambda t2, t1, w, i, t: tuple([w[i-1].lower(), t]):                       20,\n",
    "        lambda t2, t1, w, i, t: tuple([w[i+1].lower(), t]):                       20,\n",
    "        lambda t2, t1, w, i, t: tuple([w[i+1][:3].lower(), t]):                   20,\n",
    "        lambda t2, t1, w, i, t: tuple([w[i-1][:3].lower(), t]):                   20,\n",
    "        lambda t2, t1, w, i, t: tuple([w[i+1][:2].lower(), t]):                   20,\n",
    "        lambda t2, t1, w, i, t: tuple([w[i-1][:2].lower(), t]):                   20,\n",
    "        lambda t2, t1, w, i, t: tuple([w[i+1][-3:].lower(), t]):                  20,\n",
    "        lambda t2, t1, w, i, t: tuple([w[i-1][-3:].lower(), t]):                  20,\n",
    "        lambda t2, t1, w, i, t: tuple([w[i+1][-2:].lower(), t]):                  20,\n",
    "        lambda t2, t1, w, i, t: tuple([w[i-1][-2:].lower(), t]):                  20,\n",
    "        lambda t2, t1, w, i, t: tuple([w[i].isalnum(), t]):                       10,\n",
    "        lambda t2, t1, w, i, t: tuple([w[i].isalpha(), t]):                       10,\n",
    "        lambda t2, t1, w, i, t: tuple([w[i].isascii(), t]):                       10,\n",
    "        lambda t2, t1, w, i, t: tuple([w[i].isdecimal(), t]):                     10,\n",
    "        lambda t2, t1, w, i, t: tuple([w[i].isdigit(), t]):                       10,\n",
    "        lambda t2, t1, w, i, t: tuple([w[i].isnumeric(), t]):                     10,\n",
    "        lambda t2, t1, w, i, t: tuple([w[i].istitle(), t]):                       10,\n",
    "        lambda t2, t1, w, i, t: tuple([w[i].isupper(), t]):                       10,\n",
    "        lambda t2, t1, w, i, t: tuple([len(w[i]), t]):                            10,\n",
    "    }\n",
    "\n",
    "    feature_vector1 = features.create_feature_vector(dataset=train1_dataset,\n",
    "                                                     group_thresholds=group_thresholds,\n",
    "                                                     pruning=True,\n",
    "                                                     get_stats=False,\n",
    "                                                     assertions=False,\n",
    "                                                     calls_counter=False)\n",
    "\n",
    "    for feat in feature_vector1.feats:\n",
    "        print('feat_group:', feat, '| feats:', len(feat))\n",
    "    print('feat_groups:', len(feature_vector1.feats), '| total_feats:', len(feature_vector1))\n",
    "    print()\n",
    "    \n",
    "    feature_vector2 = features.create_feature_vector(dataset=train2_dataset,\n",
    "                                                     group_thresholds=group_thresholds,\n",
    "                                                     pruning=True,\n",
    "                                                     get_stats=False,\n",
    "                                                     assertions=False,\n",
    "                                                     calls_counter=False)\n",
    "\n",
    "    for feat in feature_vector2.feats:\n",
    "        print('feat_group:', feat, '| feats:', len(feat))\n",
    "    print('feat_groups:', len(feature_vector2.feats), '| total_feats:', len(feature_vector2))\n",
    "    \n",
    "    return feature_vector1, feature_vector2\n",
    "\n",
    "def retrain_model1(train1_dataset, feature_vector1):\n",
    "    np.random.seed(seed)\n",
    "    model1 = classifier.Model(version=1,\n",
    "                              w0=np.random.rand(len(feature_vector1)),\n",
    "                              tags=train1_dataset.tags,\n",
    "                              inference=classifier.viterbi,\n",
    "                              feature_vector=feature_vector1,\n",
    "                              score_func=metrics.accuracy,\n",
    "                              models_path=models_path,\n",
    "                              max_weights_history=0,\n",
    "                              save=False)\n",
    "\n",
    "    _, _, _ = model1.train(epochs=92,  # training epochs\n",
    "                           train_dataset=train1_dataset,\n",
    "                           val_dataset=None,\n",
    "                           batch_size=256,  # initial batch_size for loader\n",
    "                           weight_decay=0.0,  # lamda regularization parameter\n",
    "                           save=False,  # save model during training (requires dill module)\n",
    "                           tqdm_bar=False,  # display tqdm progress bars\n",
    "                           beam=1,  # viterbi beam size for model evaluation during training\n",
    "                           train_aprox=0,  # aproximate train_score with first train_aprox train samples\n",
    "                           val_aprox=0,  # aproximate val_score with first val_aprox train samples \n",
    "                           batch_growth=4)  # double batch_size every batch_growth epochs\n",
    "    \n",
    "    model1.feature_vector = None\n",
    "    with open(model1_file_name, 'wb') as f:\n",
    "        pickle.dump(model1, f)\n",
    "    \n",
    "    model1.feature_vector = feature_vector1\n",
    "    \n",
    "    return model1\n",
    "\n",
    "def retrain_model2(train2_dataset, feature_vector2):\n",
    "    np.random.seed(seed)\n",
    "    version = 2\n",
    "    train_save = False  # save model after each training epoch, if False model will need to be saved manually\n",
    "    beam = 1  # viterbi beam size for model evaluation during training\n",
    "    train_aprox = 0  # aproximate train_score with first train_aprox train samples\n",
    "    val_aprox = 0  # aproximate val_score with first val_aprox train samples \n",
    "    weight_decay = 0.0  # lamda regularization parameter\n",
    "    init_batch_size = 250  # batch_size for loader\n",
    "    batch_growth = 0\n",
    "    epochs = 43  # training epochs\n",
    "    tqdm_bar = False  # display tqdm progress bars\n",
    "\n",
    "    model2 = classifier.Model(version=2,\n",
    "                              w0=np.random.rand(len(feature_vector2)),\n",
    "                              tags=train2_dataset.tags,\n",
    "                              inference=classifier.viterbi,\n",
    "                              feature_vector=feature_vector2,\n",
    "                              score_func=metrics.accuracy,\n",
    "                              models_path=models_path,\n",
    "                              max_weights_history=0,\n",
    "                              save=False)\n",
    "\n",
    "    _, _, _ = model2.train(epochs=43,  # training epochs\n",
    "                           train_dataset=train2_dataset,\n",
    "                           val_dataset=None,\n",
    "                           batch_size=250,  # initial batch_size for loader\n",
    "                           weight_decay=0.0,  # lambda regularization parameter\n",
    "                           save=False,  # save model during training (requires dill module)\n",
    "                           tqdm_bar=False,  # display tqdm progress bars\n",
    "                           beam=1,  # viterbi beam size for model evaluation during training\n",
    "                           train_aprox=0,  # aproximate train_score with first train_aprox train samples\n",
    "                           val_aprox=0,  # aproximate val_score with first val_aprox train samples\n",
    "                           batch_growth=0)      # double batch_size every batch_growth epochs\n",
    "    \n",
    "    model2.feature_vector = None\n",
    "    with open(model2_file_name, 'wb') as f:\n",
    "        pickle.dump(model2, f)\n",
    "    \n",
    "    model2.feature_vector = feature_vector2\n",
    "    \n",
    "    return model2\n",
    "\n",
    "def load_trained_models(train1_dataset, train2_dataset):\n",
    "    with open(model1_file_name, \"rb\") as f:\n",
    "        model1 = pickle.load(f)\n",
    "\n",
    "    with open(model2_file_name, \"rb\") as f:\n",
    "        model2 = pickle.load(f)\n",
    "\n",
    "    model1.feature_vector, model2.feature_vector = load_feature_vectors(train1_dataset, train2_dataset)\n",
    "        \n",
    "    return model1, model2\n",
    "\n",
    "def save_wtag(dataset, comp_pred_tags, version):\n",
    "    comp_wtag_list = []\n",
    "    for i in range(len(dataset.sentences)):\n",
    "        joined_sentence = []\n",
    "        assert len(dataset.sentences[i][0]) == len(comp_pred_tags[i]), \\\n",
    "            f'i={i}, len(dataset.sentences[i][0])={len(dataset.sentences[i][0])}, len(comp_pred_tags[i])={len(comp_pred_tags[i])}'\n",
    "        for word, pred in zip(dataset.sentences[i][0], comp_pred_tags[i]):\n",
    "            joined_sentence.append('_'.join([word, pred]))\n",
    "        comp_wtag_list.append(' '.join(joined_sentence))\n",
    "\n",
    "    with open(f'comp_m{version}_321128258.wtag', 'w') as f:\n",
    "        for row in comp_wtag_list:\n",
    "            f.write(row)\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_group: FeatureGroup(tuple([w[i].lower(), t])) | feats: 14719\n",
      "feat_group: FeatureGroup(tuple([w[i][-4:].lower(), t])) | feats: 2289\n",
      "feat_group: FeatureGroup(tuple([w[i][-3:].lower(), t])) | feats: 1757\n",
      "feat_group: FeatureGroup(tuple([w[i][-2:].lower(), t])) | feats: 955\n",
      "feat_group: FeatureGroup(tuple([w[i][-1:].lower(), t])) | feats: 248\n",
      "feat_group: FeatureGroup(tuple([w[i][:4].lower(), t])) | feats: 2540\n",
      "feat_group: FeatureGroup(tuple([w[i][:3].lower(), t])) | feats: 2431\n",
      "feat_group: FeatureGroup(tuple([w[i][:2].lower(), t])) | feats: 1432\n",
      "feat_group: FeatureGroup(tuple([w[i][:1].lower(), t])) | feats: 392\n",
      "feat_group: FeatureGroup(tuple([t2, t1, t])) | feats: 5192\n",
      "feat_group: FeatureGroup(tuple([t1, t])) | feats: 908\n",
      "feat_group: FeatureGroup(tuple([t])) | feats: 44\n",
      "feat_group: FeatureGroup(tuple([w[i].islower(), t])) | feats: 75\n",
      "feat_group: FeatureGroup(tuple([any(char.isdigit() for char in w[i]), t])) | feats: 49\n",
      "feat_group: FeatureGroup(tuple([w[i-1].lower(), t])) | feats: 616\n",
      "feat_group: FeatureGroup(tuple([w[i+1].lower(), t])) | feats: 614\n",
      "feat_group: FeatureGroup(tuple([w[i+1][:3].lower(), t])) | feats: 869\n",
      "feat_group: FeatureGroup(tuple([w[i-1][:3].lower(), t])) | feats: 938\n",
      "feat_group: FeatureGroup(tuple([w[i+1][:2].lower(), t])) | feats: 1081\n",
      "feat_group: FeatureGroup(tuple([w[i-1][:2].lower(), t])) | feats: 1108\n",
      "feat_group: FeatureGroup(tuple([w[i+1][-3:].lower(), t])) | feats: 962\n",
      "feat_group: FeatureGroup(tuple([w[i-1][-3:].lower(), t])) | feats: 971\n",
      "feat_group: FeatureGroup(tuple([w[i+1][-2:].lower(), t])) | feats: 975\n",
      "feat_group: FeatureGroup(tuple([w[i-1][-2:].lower(), t])) | feats: 996\n",
      "feat_group: FeatureGroup(tuple([w[i].isalnum(), t])) | feats: 52\n",
      "feat_group: FeatureGroup(tuple([w[i].isalpha(), t])) | feats: 52\n",
      "feat_group: FeatureGroup(tuple([w[i].isascii(), t])) | feats: 42\n",
      "feat_group: FeatureGroup(tuple([w[i].isdecimal(), t])) | feats: 43\n",
      "feat_group: FeatureGroup(tuple([w[i].isdigit(), t])) | feats: 43\n",
      "feat_group: FeatureGroup(tuple([w[i].isnumeric(), t])) | feats: 43\n",
      "feat_group: FeatureGroup(tuple([w[i].istitle(), t])) | feats: 64\n",
      "feat_group: FeatureGroup(tuple([w[i].isupper(), t])) | feats: 49\n",
      "feat_group: FeatureGroup(tuple([len(w[i]), t])) | feats: 223\n",
      "feat_groups: 33 | total_feats: 42772\n",
      "\n",
      "feat_group: FeatureGroup(tuple([w[i].lower(), t])) | feats: 1736\n",
      "feat_group: FeatureGroup(tuple([w[i][-4:].lower(), t])) | feats: 170\n",
      "feat_group: FeatureGroup(tuple([w[i][-3:].lower(), t])) | feats: 165\n",
      "feat_group: FeatureGroup(tuple([w[i][-2:].lower(), t])) | feats: 145\n",
      "feat_group: FeatureGroup(tuple([w[i][-1:].lower(), t])) | feats: 96\n",
      "feat_group: FeatureGroup(tuple([w[i][:4].lower(), t])) | feats: 158\n",
      "feat_group: FeatureGroup(tuple([w[i][:3].lower(), t])) | feats: 170\n",
      "feat_group: FeatureGroup(tuple([w[i][:2].lower(), t])) | feats: 200\n",
      "feat_group: FeatureGroup(tuple([w[i][:1].lower(), t])) | feats: 133\n",
      "feat_group: FeatureGroup(tuple([t2, t1, t])) | feats: 598\n",
      "feat_group: FeatureGroup(tuple([t1, t])) | feats: 216\n",
      "feat_group: FeatureGroup(tuple([t])) | feats: 31\n",
      "feat_group: FeatureGroup(tuple([w[i].islower(), t])) | feats: 43\n",
      "feat_group: FeatureGroup(tuple([any(char.isdigit() for char in w[i]), t])) | feats: 35\n",
      "feat_group: FeatureGroup(tuple([w[i-1].lower(), t])) | feats: 28\n",
      "feat_group: FeatureGroup(tuple([w[i+1].lower(), t])) | feats: 23\n",
      "feat_group: FeatureGroup(tuple([w[i+1][:3].lower(), t])) | feats: 29\n",
      "feat_group: FeatureGroup(tuple([w[i-1][:3].lower(), t])) | feats: 35\n",
      "feat_group: FeatureGroup(tuple([w[i+1][:2].lower(), t])) | feats: 44\n",
      "feat_group: FeatureGroup(tuple([w[i-1][:2].lower(), t])) | feats: 42\n",
      "feat_group: FeatureGroup(tuple([w[i+1][-3:].lower(), t])) | feats: 30\n",
      "feat_group: FeatureGroup(tuple([w[i-1][-3:].lower(), t])) | feats: 41\n",
      "feat_group: FeatureGroup(tuple([w[i+1][-2:].lower(), t])) | feats: 49\n",
      "feat_group: FeatureGroup(tuple([w[i-1][-2:].lower(), t])) | feats: 61\n",
      "feat_group: FeatureGroup(tuple([w[i].isalnum(), t])) | feats: 24\n",
      "feat_group: FeatureGroup(tuple([w[i].isalpha(), t])) | feats: 24\n",
      "feat_group: FeatureGroup(tuple([w[i].isascii(), t])) | feats: 21\n",
      "feat_group: FeatureGroup(tuple([w[i].isdecimal(), t])) | feats: 22\n",
      "feat_group: FeatureGroup(tuple([w[i].isdigit(), t])) | feats: 22\n",
      "feat_group: FeatureGroup(tuple([w[i].isnumeric(), t])) | feats: 22\n",
      "feat_group: FeatureGroup(tuple([w[i].istitle(), t])) | feats: 27\n",
      "feat_group: FeatureGroup(tuple([w[i].isupper(), t])) | feats: 22\n",
      "feat_group: FeatureGroup(tuple([len(w[i]), t])) | feats: 86\n",
      "feat_groups: 33 | total_feats: 4548\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "train1_dataset, test1_dataset, comp1_dataset, train2_dataset, comp2_dataset = load_datasets()\n",
    "\n",
    "# # retrain models\n",
    "# feature_vector1, feature_vector2 = load_feature_vectors(train1_dataset, train2_dataset)\n",
    "# model1 = retrain_model1(train1_dataset, feature_vector1) \n",
    "# model2 = retrain_model2(train2_dataset, feature_vector2)\n",
    "\n",
    "# load models\n",
    "model1, model2 = load_trained_models(train1_dataset, train2_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train1_dataset, test1_dataset, comp1_dataset, train2_dataset, comp2_dataset = load_datasets()\n",
    "\n",
    "# model1_test1 = classifier.load_model(from_file='models/V1.2/model_V1.2_E092_beam1_test1_acc0.9532.pth', prints=False)\n",
    "# model1 = classifier.load_model(from_file='models/V1.2/model_V1.2_E092_beam10_comp_acc0.9275.pth', prints=False)\n",
    "# model2 = classifier.load_model(from_file='models/V2.1/model_V2.1_E043_beam1_comp_acc0.9264.pth', prints=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test1_pred_tags, test1_true_tags = model1_test1.comp_preds[1]['pred_tags'], model1_test1.comp_preds[1]['true_tags']\n",
    "# test1_accuracy = model1.score_func(test1_pred_tags, test1_true_tags)\n",
    "# test1_confusion_matrix, test1_tags_accuracy = metrics.confusion_matrix(train1_dataset.tags, test1_pred_tags, test1_true_tags)\n",
    "\n",
    "# worst10_test1_confusion_matrix = test1_confusion_matrix.loc[list(test1_tags_accuracy.keys())[:10], list(test1_tags_accuracy.keys())[:10]]\n",
    "# worst10_test1_tags_accuracy = list(test1_tags_accuracy)[:10]\n",
    "\n",
    "# # comp1_pred_tags, _ = model1.predict(comp1_dataset.sentences, beam=5, tqdm_bar=False)\n",
    "# # comp2_pred_tags, _ = model2.predict(comp2_dataset.sentences, beam=1, tqdm_bar=False)\n",
    "# comp1_5_pred_tags, _ = model1.comp_preds[5]['pred_tags'], None\n",
    "# comp1_10_pred_tags, _ = model1.comp_preds[10]['pred_tags'], None\n",
    "# comp2_pred_tags, _ = model2.comp_preds[1]['pred_tags'], None\n",
    "\n",
    "# # save_wtag(comp1_dataset, comp1_pred_tags, 1)\n",
    "# # save_wtag(comp2_dataset, comp2_pred_tags, 2)\n",
    "\n",
    "# # model1.plot(['train_loss'], 'loss', 'loss', scale='linear', basey=10)\n",
    "# # model1.plot(['batch_size'], 'batch_size', 'batch_size', scale='log', basey=2)\n",
    "\n",
    "# # model2.plot(['train_loss'], 'loss', 'loss', scale='linear', basey=10)\n",
    "# # model2.plot(['batch_size'], 'batch_size', 'batch_size', scale='log', basey=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comp1_pred_dataset = preprocess.Dataset('/mnt/d/Downloads/comp_m1_312146897.wtag')\n",
    "# comp2_pred_dataset = preprocess.Dataset('/mnt/d/Downloads/comp_m2_312146897.wtag')\n",
    "comp1_pred_dataset = preprocess.Dataset('/mnt/d/Downloads/comp_m1_312146897.wtag')\n",
    "comp2_pred_dataset = preprocess.Dataset('/mnt/d/Downloads/comp_m2_312146897.wtag')\n",
    "comp1_true_dataset = preprocess.Dataset(os.path.join(data_path, 'comp1_tagged.wtag'))\n",
    "comp2_true_dataset = preprocess.Dataset(os.path.join(data_path, 'comp2_tagged.wtag'))\n",
    "\n",
    "comp1_accuracy = model1.score_func([sentence[1] for sentence in comp1_pred_dataset.sentences],\n",
    "                                   [sentence[1] for sentence in comp1_true_dataset.sentences])\n",
    "comp2_accuracy = model1.score_func([sentence[1] for sentence in comp2_pred_dataset.sentences],\n",
    "                                   [sentence[1] for sentence in comp2_true_dataset.sentences])\n",
    "\n",
    "# comp2_accuracy = model2.score_func([sentence[1] for sentence in comp2_pred_dataset.sentences],\n",
    "#                                    [sentence[1] for sentence in comp2_true_dataset.sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp1_accuracy: 0.005428559311251537\n",
      "comp2_accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# print('test1_accuracy:', test1_accuracy)\n",
    "print('comp1_accuracy:', comp1_accuracy)\n",
    "print('comp2_accuracy:', comp2_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/c/Users/alexz/OneDrive/MainEnv/nlp/MEMM_Part_of_Speech_Tagging'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9133936759838909"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comp2_true_dataset = preprocess.Dataset(os.path.join(data_path, 'comp2_tagged.wtag'))\n",
    "# comp2_pred_dataset = preprocess.Dataset('test_t2_word3_beam6.txt')\n",
    "# comp2_accuracy = model2.score_func([sentence[1] for sentence in comp2_pred_dataset.sentences],\n",
    "#                                    [sentence[1] for sentence in comp2_true_dataset.sentences])\n",
    "# comp2_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#']\n",
      "['NNS', 'VBD', 'EX', 'VBD', 'DT', 'JJ', 'NNS', 'IN', 'NNP', 'NNP', 'CC', 'NNP', 'NNP', 'NNP', 'NNP', 'NNS', 'IN', 'NNS', 'IN', 'JJ', 'NN', 'POS', 'JJ', 'NN', 'IN', 'JJ', 'NN', 'NN', 'NN', 'NN', 'NNS', 'VBD', 'TO', 'VB', 'NN', 'IN', 'JJ', 'NNS', '.']\n"
     ]
    }
   ],
   "source": [
    "print(comp1_pred_dataset.sentences[0][1])\n",
    "print(comp1_true_dataset.sentences[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp1_accuracy: 0.005428559311251537\n",
      "comp2_accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class Dataset():\n",
    "    def __init__(self, file_name, labeled=True, tags=None):\n",
    "        \"\"\"\n",
    "        args:\n",
    "            * file_name\n",
    "            * labeled - is the dataset labeled?\n",
    "            * tags - if dataset is not labeled, what are the tags\n",
    "        \"\"\"\n",
    "        self.words_counter = 0\n",
    "        self.sentences = []\n",
    "        self.labeled = labeled\n",
    "        self.tags = set()\n",
    "        if not labeled and tags:\n",
    "            self.tags = set(tags)\n",
    "        with open(file_name, 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                words = []\n",
    "                tags = []\n",
    "                for word_tag in line.split():\n",
    "                    if self.labeled:\n",
    "                        word, tag = word_tag.split('_')\n",
    "                        self.tags.add(tag)\n",
    "                    else:\n",
    "                        word = word_tag\n",
    "                        tag = None\n",
    "                    tags.append(tag)\n",
    "                    words.append(word)\n",
    "                    self.words_counter += 1\n",
    "                    \n",
    "                self.sentences.append((words, tags))\n",
    "        self.batch_loader = self.sentences.copy()\n",
    "        self.shuffled = False\n",
    "        \n",
    "    def _init_loader(self, shuffle, seed, new=False):\n",
    "        new_batch_loader = self.sentences.copy()\n",
    "        if shuffle:\n",
    "            np.random.seed(seed)\n",
    "            np.random.shuffle(new_batch_loader)\n",
    "        self.shuffled = shuffle\n",
    "        if new:\n",
    "            self.batch_loader = new_batch_loader\n",
    "        else:\n",
    "            self.batch_loader.extend(new_batch_loader)\n",
    "\n",
    "    def load_batch(self, batch_size=None, shuffle=False, seed=42):\n",
    "        \"\"\"\n",
    "        args:\n",
    "            * batch_size=None - batch_size to load, if batch_size=None -> batch_size=len(self.sentences)\n",
    "            * shuffle - reshuffle loaded sentences\n",
    "            * seed - set random.seed\n",
    "        return:\n",
    "            * generator that iterates batch_size of sentences and words yields tuples of t2, t1, w, i, t\n",
    "        \"\"\"\n",
    "        if not batch_size:\n",
    "            batch_size = len(self.sentences)\n",
    "        if self.shuffled != shuffle:\n",
    "            self._init_loader(shuffle, seed, new=True)\n",
    "        if len(self.batch_loader) < batch_size:\n",
    "            self._init_loader(shuffle, seed)\n",
    "            \n",
    "        sentences = self.batch_loader[:batch_size]\n",
    "        del self.batch_loader[:batch_size]\n",
    "        for w, tags in sentences:\n",
    "            t1, t = '*', '*'\n",
    "            for i in range(len(w)):\n",
    "                t2, t1, t = t1, t, tags[i]\n",
    "                yield t2, t1, w, i, t\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.words_counter\n",
    "\n",
    "    def __iter__(self):\n",
    "        for w, tags in self.sentences:\n",
    "            t1, t = '*', '*'\n",
    "            for i in range(len(w)):\n",
    "                t2, t1, t = t1, t, tags[i]\n",
    "                yield t2, t1, w, i, t\n",
    "\n",
    "\n",
    "def accuracy(pred_tags, true_tags):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for preds, tags in zip(pred_tags, true_tags):\n",
    "        if isinstance(preds, list):\n",
    "            for pred, tag in zip(preds, tags):\n",
    "                total += 1\n",
    "                if pred == tag:\n",
    "                    correct += 1\n",
    "        else:\n",
    "            total += 1\n",
    "            if preds == tags:\n",
    "                correct += 1\n",
    "\n",
    "    if total > 0:\n",
    "        return float(correct)/total\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "comp1_pred_dataset = Dataset('/mnt/d/Downloads/comp_m1_312146897.wtag')\n",
    "comp1_true_dataset = Dataset(os.path.join(data_path, 'comp1_tagged.wtag'))\n",
    "comp1_accuracy = accuracy([sentence[1] for sentence in comp1_pred_dataset.sentences],\n",
    "                          [sentence[1] for sentence in comp1_true_dataset.sentences])\n",
    "\n",
    "comp2_pred_dataset = Dataset('/mnt/d/Downloads/comp_m2_312146897.wtag')\n",
    "comp2_true_dataset = Dataset(os.path.join(data_path, 'comp2_tagged.wtag'))\n",
    "comp2_accuracy = accuracy([sentence[1] for sentence in comp2_pred_dataset.sentences],\n",
    "                          [sentence[1] for sentence in comp2_true_dataset.sentences])\n",
    "\n",
    "print('comp1_accuracy:', comp1_accuracy)\n",
    "print('comp2_accuracy:', comp2_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_hw1",
   "language": "python",
   "name": "nlp_hw1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
