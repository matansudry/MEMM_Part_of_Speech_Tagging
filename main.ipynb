{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import inspect\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from utils import preprocess, features, classifier, metrics, logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "models_path = 'models'  # folder of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>version</th>\n",
       "      <th>epoch</th>\n",
       "      <th>seed</th>\n",
       "      <th>init</th>\n",
       "      <th>features</th>\n",
       "      <th>datasets</th>\n",
       "      <th>train_time</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>train_score</th>\n",
       "      <th>val_score</th>\n",
       "      <th>train_aprox</th>\n",
       "      <th>val_aprox</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>beam</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [version, epoch, seed, init, features, datasets, train_time, timestamp, train_loss, val_loss, train_score, val_score, train_aprox, val_aprox, batch_size, weight_decay, beam, description]\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger2 = logging.Logger('log/log2.csv')\n",
    "logger2.leadboard(col='val_score', top=5)\n",
    "# logger2.init_log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>version</th>\n",
       "      <th>epoch</th>\n",
       "      <th>seed</th>\n",
       "      <th>init</th>\n",
       "      <th>features</th>\n",
       "      <th>datasets</th>\n",
       "      <th>train_time</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>train_score</th>\n",
       "      <th>val_score</th>\n",
       "      <th>train_aprox</th>\n",
       "      <th>val_aprox</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>beam</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>90</td>\n",
       "      <td>42</td>\n",
       "      <td>def w0_uniform_0_1():\\n    return np.random.ra...</td>\n",
       "      <td>def create_feats(prints=True):\\n    group_thre...</td>\n",
       "      <td>def load_datasets():\\n    train_dataset = prep...</td>\n",
       "      <td>986.881775</td>\n",
       "      <td>10:43:00 25-04-2020</td>\n",
       "      <td>1.617005</td>\n",
       "      <td>3.183868</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.927096</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>train1, comp1_acc=0.9270961448746766, 33 feat_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>87</td>\n",
       "      <td>42</td>\n",
       "      <td>def w0_uniform_0_1():\\n    return np.random.ra...</td>\n",
       "      <td>def create_feats(prints=True):\\n    group_thre...</td>\n",
       "      <td>def load_datasets():\\n    train_dataset = prep...</td>\n",
       "      <td>947.885913</td>\n",
       "      <td>10:03:56 25-04-2020</td>\n",
       "      <td>1.653636</td>\n",
       "      <td>3.198782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.924679</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>train1, comp1_acc=0.9246787395563849, 33 feat_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   version  epoch  seed                                               init  \\\n",
       "1       12     90    42  def w0_uniform_0_1():\\n    return np.random.ra...   \n",
       "0       12     87    42  def w0_uniform_0_1():\\n    return np.random.ra...   \n",
       "\n",
       "                                            features  \\\n",
       "1  def create_feats(prints=True):\\n    group_thre...   \n",
       "0  def create_feats(prints=True):\\n    group_thre...   \n",
       "\n",
       "                                            datasets  train_time  \\\n",
       "1  def load_datasets():\\n    train_dataset = prep...  986.881775   \n",
       "0  def load_datasets():\\n    train_dataset = prep...  947.885913   \n",
       "\n",
       "             timestamp  train_loss  val_loss  train_score  val_score  \\\n",
       "1  10:43:00 25-04-2020    1.617005  3.183868          0.0   0.927096   \n",
       "0  10:03:56 25-04-2020    1.653636  3.198782          0.0   0.924679   \n",
       "\n",
       "   train_aprox  val_aprox  batch_size  weight_decay  beam  \\\n",
       "1            0          0        5000           0.0     1   \n",
       "0            0          0        5000           0.0     1   \n",
       "\n",
       "                                         description  \n",
       "1  train1, comp1_acc=0.9270961448746766, 33 feat_...  \n",
       "0  train1, comp1_acc=0.9246787395563849, 33 feat_...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger1 = logging.Logger('log/log1.csv')\n",
    "logger1.leadboard(col='val_score', top=5)\n",
    "# logger1.init_log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets():\n",
    "#     train_dataset = preprocess.Dataset('data/train1.wtag')\n",
    "#     val_dataset = preprocess.Dataset('data/comp1_tagged.wtag')\n",
    "\n",
    "    train_dataset = preprocess.Dataset('data/train2.wtag')\n",
    "    val_dataset = preprocess.Dataset('data/comp2_tagged.wtag')\n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "train_dataset, val_dataset = load_datasets()\n",
    "tags = train_dataset.tags.union(val_dataset.tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_vector creation time: 0.17348623275756836 sec\n",
      "\n",
      "feat_group: FeatureGroup(tuple([w[i].lower(), t])) | feats: 1736\n",
      "feat_group: FeatureGroup(tuple([w[i][-4:].lower(), t])) | feats: 170\n",
      "feat_group: FeatureGroup(tuple([w[i][-3:].lower(), t])) | feats: 165\n",
      "feat_group: FeatureGroup(tuple([w[i][-2:].lower(), t])) | feats: 145\n",
      "feat_group: FeatureGroup(tuple([w[i][-1:].lower(), t])) | feats: 96\n",
      "feat_group: FeatureGroup(tuple([w[i][:4].lower(), t])) | feats: 158\n",
      "feat_group: FeatureGroup(tuple([w[i][:3].lower(), t])) | feats: 170\n",
      "feat_group: FeatureGroup(tuple([w[i][:2].lower(), t])) | feats: 200\n",
      "feat_group: FeatureGroup(tuple([w[i][:1].lower(), t])) | feats: 133\n",
      "feat_group: FeatureGroup(tuple([t2, t1, t])) | feats: 598\n",
      "feat_group: FeatureGroup(tuple([t1, t])) | feats: 216\n",
      "feat_group: FeatureGroup(tuple([t])) | feats: 31\n",
      "feat_group: FeatureGroup(tuple([w[i].islower(), t])) | feats: 43\n",
      "feat_group: FeatureGroup(tuple([any(char.isdigit() for char in w[i]), t])) | feats: 35\n",
      "feat_group: FeatureGroup(tuple([w[i-1].lower(), t])) | feats: 28\n",
      "feat_group: FeatureGroup(tuple([w[i+1].lower(), t])) | feats: 23\n",
      "feat_group: FeatureGroup(tuple([w[i+1][:3].lower(), t])) | feats: 29\n",
      "feat_group: FeatureGroup(tuple([w[i-1][:3].lower(), t])) | feats: 35\n",
      "feat_group: FeatureGroup(tuple([w[i+1][:2].lower(), t])) | feats: 44\n",
      "feat_group: FeatureGroup(tuple([w[i-1][:2].lower(), t])) | feats: 42\n",
      "feat_group: FeatureGroup(tuple([w[i+1][-3:].lower(), t])) | feats: 30\n",
      "feat_group: FeatureGroup(tuple([w[i-1][-3:].lower(), t])) | feats: 41\n",
      "feat_group: FeatureGroup(tuple([w[i+1][-2:].lower(), t])) | feats: 49\n",
      "feat_group: FeatureGroup(tuple([w[i-1][-2:].lower(), t])) | feats: 61\n",
      "feat_group: FeatureGroup(tuple([w[i].isalnum(), t])) | feats: 24\n",
      "feat_group: FeatureGroup(tuple([w[i].isalpha(), t])) | feats: 24\n",
      "feat_group: FeatureGroup(tuple([w[i].isascii(), t])) | feats: 21\n",
      "feat_group: FeatureGroup(tuple([w[i].isdecimal(), t])) | feats: 22\n",
      "feat_group: FeatureGroup(tuple([w[i].isdigit(), t])) | feats: 22\n",
      "feat_group: FeatureGroup(tuple([w[i].isnumeric(), t])) | feats: 22\n",
      "feat_group: FeatureGroup(tuple([w[i].istitle(), t])) | feats: 27\n",
      "feat_group: FeatureGroup(tuple([w[i].isupper(), t])) | feats: 22\n",
      "feat_group: FeatureGroup(tuple([len(w[i]), t])) | feats: 86\n",
      "feat_groups: 33 | total_feats: 4548\n"
     ]
    }
   ],
   "source": [
    "def create_feats(prints=True):\n",
    "    group_thresholds = {\n",
    "        # -------------------------------- feature --------------------- | -- Threshold --\n",
    "        lambda t2, t1, w, i, t: tuple([w[i].lower(), t]):                         0,     # mandatory feature f100\n",
    "        lambda t2, t1, w, i, t: tuple([w[i][-4:].lower(), t]):                    5,     # mandatory feature f101\n",
    "        lambda t2, t1, w, i, t: tuple([w[i][-3:].lower(), t]):                    5,     # mandatory feature f101\n",
    "        lambda t2, t1, w, i, t: tuple([w[i][-2:].lower(), t]):                    5,     # mandatory feature f101\n",
    "        lambda t2, t1, w, i, t: tuple([w[i][-1:].lower(), t]):                    5,     # mandatory feature f101\n",
    "        lambda t2, t1, w, i, t: tuple([w[i][:4].lower(), t]):                     5,     # mandatory feature f102\n",
    "        lambda t2, t1, w, i, t: tuple([w[i][:3].lower(), t]):                     5,     # mandatory feature f102\n",
    "        lambda t2, t1, w, i, t: tuple([w[i][:2].lower(), t]):                     5,     # mandatory feature f102\n",
    "        lambda t2, t1, w, i, t: tuple([w[i][:1].lower(), t]):                     5,     # mandatory feature f102\n",
    "        lambda t2, t1, w, i, t: tuple([t2, t1, t]):                               1,     # mandatory feature f103\n",
    "        lambda t2, t1, w, i, t: tuple([t1, t]):                                   1,     # mandatory feature f104\n",
    "        lambda t2, t1, w, i, t: tuple([t]):                                       1,     # mandatory feature f105\n",
    "        lambda t2, t1, w, i, t: tuple([w[i].islower(), t]):                       1,     # mandatory feature has_uppercase\n",
    "        lambda t2, t1, w, i, t: tuple([any(char.isdigit() for char in w[i]), t]): 1,     # mandatory feature has_digits\n",
    "        lambda t2, t1, w, i, t: tuple([w[i-1].lower(), t]):                       20,\n",
    "        lambda t2, t1, w, i, t: tuple([w[i+1].lower(), t]):                       20,\n",
    "        lambda t2, t1, w, i, t: tuple([w[i+1][:3].lower(), t]):                   20,\n",
    "        lambda t2, t1, w, i, t: tuple([w[i-1][:3].lower(), t]):                   20,\n",
    "        lambda t2, t1, w, i, t: tuple([w[i+1][:2].lower(), t]):                   20,\n",
    "        lambda t2, t1, w, i, t: tuple([w[i-1][:2].lower(), t]):                   20,\n",
    "        lambda t2, t1, w, i, t: tuple([w[i+1][-3:].lower(), t]):                  20,\n",
    "        lambda t2, t1, w, i, t: tuple([w[i-1][-3:].lower(), t]):                  20,\n",
    "        lambda t2, t1, w, i, t: tuple([w[i+1][-2:].lower(), t]):                  20,\n",
    "        lambda t2, t1, w, i, t: tuple([w[i-1][-2:].lower(), t]):                  20,\n",
    "        lambda t2, t1, w, i, t: tuple([w[i].isalnum(), t]):                       10,\n",
    "        lambda t2, t1, w, i, t: tuple([w[i].isalpha(), t]):                       10,\n",
    "        lambda t2, t1, w, i, t: tuple([w[i].isascii(), t]):                       10,\n",
    "        lambda t2, t1, w, i, t: tuple([w[i].isdecimal(), t]):                     10,\n",
    "        lambda t2, t1, w, i, t: tuple([w[i].isdigit(), t]):                       10,\n",
    "        lambda t2, t1, w, i, t: tuple([w[i].isnumeric(), t]):                     10,\n",
    "        lambda t2, t1, w, i, t: tuple([w[i].istitle(), t]):                       10,\n",
    "        lambda t2, t1, w, i, t: tuple([w[i].isupper(), t]):                       10,\n",
    "        lambda t2, t1, w, i, t: tuple([len(w[i]), t]):                            10,\n",
    "    }\n",
    "\n",
    "    tic = time.time()\n",
    "    feature_vector = features.create_feature_vector(dataset=train_dataset,\n",
    "                                                    group_thresholds=group_thresholds,\n",
    "                                                    pruning=True,\n",
    "                                                    get_stats=False,\n",
    "                                                    assertions=True,\n",
    "                                                    calls_counter=False)\n",
    "\n",
    "    if prints:\n",
    "        print('feature_vector creation time:', time.time() - tic, 'sec\\n')\n",
    "        for feat in feature_vector.feats:\n",
    "            print('feat_group:', feat, '| feats:', len(feat))\n",
    "    print('feat_groups:', len(feature_vector.feats), '| total_feats:', len(feature_vector))\n",
    "    return feature_vector\n",
    "\n",
    "feature_vector = create_feats(prints=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_feats(prints=True):\n",
    "#     group_thresholds = {\n",
    "#         # -------------------------------- feature --------------------- | -- Threshold --\n",
    "#         lambda t2, t1, w, i, t: tuple([w[i].lower(), t]):                         0,     # mandatory feature f100\n",
    "# #         lambda t2, t1, w, i, t: tuple([w[i-1].lower(), w[i].lower(), w[i+1].lower(), t]):                 10,\n",
    "# #         lambda t2, t1, w, i, t: tuple([w[i-2].lower(), w[i-1].lower(), w[i].lower(), t]):                 10,\n",
    "# #         lambda t2, t1, w, i, t: tuple([w[i].lower(), w[i+1].lower(), w[i+2].lower(), t]):                 10,\n",
    "#         lambda t2, t1, w, i, t: tuple([w[i].lower(), t]):                         0,\n",
    "#         lambda t2, t1, w, i, t: tuple([w[i][-4:].lower(), t]):                    5,     # mandatory feature f101\n",
    "#         lambda t2, t1, w, i, t: tuple([w[i][-3:].lower(), t]):                    5,     # mandatory feature f101\n",
    "#         lambda t2, t1, w, i, t: tuple([w[i][-2:].lower(), t]):                    5,     # mandatory feature f101\n",
    "#         lambda t2, t1, w, i, t: tuple([w[i][-1:].lower(), t]):                    5,     # mandatory feature f101\n",
    "#         lambda t2, t1, w, i, t: tuple([w[i][:4].lower(), t]):                     5,     # mandatory feature f102\n",
    "#         lambda t2, t1, w, i, t: tuple([w[i][:3].lower(), t]):                     5,     # mandatory feature f102\n",
    "#         lambda t2, t1, w, i, t: tuple([w[i][:2].lower(), t]):                     5,     # mandatory feature f102\n",
    "#         lambda t2, t1, w, i, t: tuple([w[i][:1].lower(), t]):                     5,     # mandatory feature f102\n",
    "#         lambda t2, t1, w, i, t: tuple([t2, t1, t]):                               1,     # mandatory feature f103\n",
    "#         lambda t2, t1, w, i, t: tuple([t1, t]):                                   1,     # mandatory feature f104\n",
    "#         lambda t2, t1, w, i, t: tuple([t]):                                       0,     # mandatory feature f105\n",
    "#         lambda t2, t1, w, i, t: tuple([w[i].islower(), t]):                       0,     # mandatory feature has_uppercase (inverted)\n",
    "#         lambda t2, t1, w, i, t: tuple([any(char.isdigit() for char in w[i]), t]): 0,     # mandatory feature has_digits\n",
    "#         lambda t2, t1, w, i, t: tuple([w[i-1].lower(), t]):                       20,\n",
    "#         lambda t2, t1, w, i, t: tuple([w[i+1].lower(), t]):                       20,\n",
    "#         lambda t2, t1, w, i, t: tuple([w[i+1][:3].lower(), t]):                   20,\n",
    "#         lambda t2, t1, w, i, t: tuple([w[i-1][:3].lower(), t]):                   20,\n",
    "#         lambda t2, t1, w, i, t: tuple([w[i+1][:2].lower(), t]):                   20,\n",
    "#         lambda t2, t1, w, i, t: tuple([w[i-1][:2].lower(), t]):                   20,\n",
    "#         lambda t2, t1, w, i, t: tuple([w[i+1][-3:].lower(), t]):                  20,\n",
    "#         lambda t2, t1, w, i, t: tuple([w[i-1][-3:].lower(), t]):                  20,\n",
    "#         lambda t2, t1, w, i, t: tuple([w[i+1][-2:].lower(), t]):                  20,\n",
    "#         lambda t2, t1, w, i, t: tuple([w[i-1][-2:].lower(), t]):                  20,\n",
    "#         lambda t2, t1, w, i, t: tuple([w[i].isalnum(), t]):                       0,\n",
    "#         lambda t2, t1, w, i, t: tuple([w[i].isalpha(), t]):                       0,\n",
    "#         lambda t2, t1, w, i, t: tuple([w[i].isascii(), t]):                       0,\n",
    "#         lambda t2, t1, w, i, t: tuple([w[i].isdecimal(), t]):                     0,\n",
    "#         lambda t2, t1, w, i, t: tuple([w[i].isdigit(), t]):                       0,\n",
    "#         lambda t2, t1, w, i, t: tuple([w[i].isnumeric(), t]):                     0,\n",
    "#         lambda t2, t1, w, i, t: tuple([w[i].istitle(), t]):                       0,\n",
    "#         lambda t2, t1, w, i, t: tuple([w[i].isupper(), t]):                       0,\n",
    "#         lambda t2, t1, w, i, t: tuple(['-' in w[i], t]):                          0,\n",
    "#         lambda t2, t1, w, i, t: tuple(['.' in w[i], t]):                          0,\n",
    "#         lambda t2, t1, w, i, t: tuple([',' in w[i], t]):                          0,\n",
    "#         lambda t2, t1, w, i, t: tuple(['\\/' in w[i], t]):                         0,\n",
    "#         lambda t2, t1, w, i, t: tuple([len(w[i]), t]):                            0,\n",
    "#         lambda t2, t1, w, i, t: tuple([len(w), t]):                               5,\n",
    "#         lambda t2, t1, w, i, t: tuple([i, t]):                                    10,\n",
    "#         lambda t2, t1, w, i, t: tuple([i==len(w)-1, t]):                          0,\n",
    "\n",
    "#         lambda t2, t1, w, i, t: tuple([w[i-1].isalnum(), t]):                     0,\n",
    "#         lambda t2, t1, w, i, t: tuple([w[i-1].isalpha(), t]):                     0,\n",
    "#         lambda t2, t1, w, i, t: tuple([w[i-1].isascii(), t]):                     0,\n",
    "#         lambda t2, t1, w, i, t: tuple([w[i-1].isdecimal(), t]):                   0,\n",
    "#         lambda t2, t1, w, i, t: tuple([w[i-1].isdigit(), t]):                     0,\n",
    "#         lambda t2, t1, w, i, t: tuple([w[i-1].isnumeric(), t]):                   0,\n",
    "#         lambda t2, t1, w, i, t: tuple([w[i-1].istitle(), t]):                     0,\n",
    "#         lambda t2, t1, w, i, t: tuple([w[i-1].isupper(), t]):                     0,\n",
    "\n",
    "#         lambda t2, t1, w, i, t: tuple([w[i+1].isalnum(), t]):                     0,\n",
    "#         lambda t2, t1, w, i, t: tuple([w[i+1].isalpha(), t]):                     0,\n",
    "#         lambda t2, t1, w, i, t: tuple([w[i+1].isascii(), t]):                     0,\n",
    "#         lambda t2, t1, w, i, t: tuple([w[i+1].isdecimal(), t]):                   0,\n",
    "#         lambda t2, t1, w, i, t: tuple([w[i+1].isdigit(), t]):                     0,\n",
    "#         lambda t2, t1, w, i, t: tuple([w[i+1].isnumeric(), t]):                   0,\n",
    "#         lambda t2, t1, w, i, t: tuple([w[i+1].istitle(), t]):                     0,\n",
    "#         lambda t2, t1, w, i, t: tuple([w[i+1].isupper(), t]):                     0,\n",
    "#     }\n",
    "\n",
    "#     tic = time.time()\n",
    "#     feature_vector = features.create_feature_vector(dataset=train_dataset,\n",
    "#                                                     group_thresholds=group_thresholds,\n",
    "#                                                     pruning=True,\n",
    "#                                                     get_stats=False,\n",
    "#                                                     assertions=True,\n",
    "#                                                     calls_counter=False)\n",
    "\n",
    "#     if prints:\n",
    "#         print('feature_vector creation time:', time.time() - tic, 'sec\\n')\n",
    "#         for feat in feature_vector.feats:\n",
    "#             print('feat_group:', feat, '| feats:', len(feat))\n",
    "#     print('feat_groups:', len(feature_vector.feats), '| total_feats:', len(feature_vector))\n",
    "#     return feature_vector\n",
    "\n",
    "# feature_vector = create_feats(prints=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w0_uniform_0_1_centered_normalized():\n",
    "    w0 = np.random.rand(len(feature_vector))\n",
    "    w0 -= w0.mean()\n",
    "    w0 /= w0.std()\n",
    "    return w0\n",
    "\n",
    "def w0_uniform_0_1_normalized():\n",
    "    w0 = np.random.rand(len(feature_vector))\n",
    "    w0 /= w0.std()\n",
    "    return w0\n",
    "\n",
    "def w0_uniform_0_1_centered():\n",
    "    w0 = np.random.rand(len(feature_vector))\n",
    "    w0 -= w0.mean()\n",
    "    return w0\n",
    "\n",
    "def w0_uniform_0_1():\n",
    "    return np.random.rand(len(feature_vector))\n",
    "\n",
    "def w0_xavier():\n",
    "    return np.random.randn(len(feature_vector))*np.sqrt(1/len(feature_vector))\n",
    "\n",
    "def w0_zero():\n",
    "    return np.zeros(len(feature_vector)).astype(np.float32)\n",
    "\n",
    "w0_init = w0_uniform_0_1\n",
    "w0 = w0_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model version: 2.1\n",
      "epochs: 44\n",
      "train_time: 40.407\n",
      "\n",
      "last train_loss: 1.376101\n",
      "last val_loss: 6.598743\n",
      "last train_score: 0.000000\n",
      "last val_score: 0.000000\n",
      "best val_score: 0.0000 at epoch 44\n"
     ]
    }
   ],
   "source": [
    "model = classifier.load_model(version=2.1,\n",
    "                              models_path=models_path,\n",
    "                              epoch=-1,\n",
    "                              seed=42,\n",
    "                              prints=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 15\n",
    "epoch = -1\n",
    "load = False  # load last weights, log and feature_vector into model\n",
    "\n",
    "model = classifier.Model(version=version,\n",
    "                         w0=w0_init(),\n",
    "                         tags=train_dataset.tags,\n",
    "                         inference=classifier.viterbi,\n",
    "                         feature_vector=feature_vector,\n",
    "                         score_func=metrics.accuracy,\n",
    "                         models_path=models_path,\n",
    "                         max_weights_history=5,\n",
    "                         save=False)\n",
    "\n",
    "if load:\n",
    "    model.load(weights=True, weights_history=True, feature_vector=True, log=True, epoch=epoch, prints=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_save = False  # save model after each training epoch, if False model will need to be saved manually\n",
    "beam = 1  # viterbi beam size for model evaluation during training\n",
    "train_aprox = 0  # aproximate train_score with first train_aprox train samples\n",
    "val_aprox = 0  # aproximate val_score with first val_aprox train samples \n",
    "weight_decay = 0.0  # lamda regularization parameter\n",
    "init_batch_size = 250  # batch_size for loader\n",
    "batch_growth = 0\n",
    "epochs = 200  # training epochs\n",
    "tqdm_bar = False  # display tqdm progress bars\n",
    "description = f\"train2, {len(feature_vector.feats)} feat_groups, {len(feature_vector)} total_feats\"\n",
    "\n",
    "v_min, f_min, d_min = model.train(epochs=epochs,\n",
    "                                  train_dataset=train_dataset,\n",
    "                                  val_dataset=val_dataset,\n",
    "                                  batch_size=init_batch_size,\n",
    "                                  weight_decay=weight_decay,\n",
    "                                  save=train_save,\n",
    "                                  tqdm_bar=tqdm_bar,\n",
    "                                  beam=beam,\n",
    "                                  train_aprox=train_aprox,\n",
    "                                  val_aprox=val_aprox,\n",
    "                                  batch_growth=batch_growth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # recalculate best INDs\n",
    "# best_loss = 9999.9\n",
    "# for i in model.log.index:\n",
    "#     best = model.log.loc[i]['val_loss'] < best_loss\n",
    "#     if best:\n",
    "#         model.log.loc[i, 'best'] = True\n",
    "#         best_loss = model.log.loc[i]['val_loss']\n",
    "# model.save(epoch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model version: 2.2\n",
      "epochs: 30\n",
      "train_time: 15.766\n",
      "\n",
      "last train_loss: 2.817186\n",
      "last val_loss: 6.461998\n",
      "last train_score: 0.000000\n",
      "last val_score: 0.000000\n",
      "best val_score: 0.0000 at epoch 30\n"
     ]
    }
   ],
   "source": [
    "model = classifier.load_model(version=2.2,\n",
    "                              models_path=models_path,\n",
    "                              epoch=-1,\n",
    "                              seed=42,\n",
    "                              prints=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [13:49<00:00,  1.21it/s, acc=0.923]\n"
     ]
    }
   ],
   "source": [
    "aprox_num = 1000  # max samples to aproximate score\n",
    "display_all = False\n",
    "beam_stats = {}\n",
    "dataset = val_dataset\n",
    "logger = logger2\n",
    "\n",
    "for predict_beam in [1]:  # viterbi beam size\n",
    "    beam_stats[predict_beam] = {}\n",
    "    beam_stats[predict_beam]['pred_tags'] = []\n",
    "    beam_stats[predict_beam]['true_tags'] = []\n",
    "    pbar = tqdm(dataset.sentences[:aprox_num])\n",
    "    for sentence in pbar:\n",
    "        preds = model(sentence[0], predict_beam)\n",
    "        beam_stats[predict_beam]['pred_tags'].append(preds)\n",
    "        beam_stats[predict_beam]['true_tags'].append(sentence[1])\n",
    "\n",
    "        if display_all:\n",
    "            display(pd.DataFrame((sentence[0], sentence[1], preds), index=('words', 'tags', 'preds')))\n",
    "        pbar.set_postfix(acc=model.score_func(beam_stats[predict_beam]['pred_tags'],\n",
    "                                              beam_stats[predict_beam]['true_tags']),\n",
    "                         refresh=False)\n",
    "\n",
    "    beam_stats[predict_beam]['matrix'], beam_stats[predict_beam]['worst'] = \\\n",
    "                                        metrics.confusion_matrix(tags,\n",
    "                                                                 beam_stats[predict_beam]['pred_tags'],\n",
    "                                                                 beam_stats[predict_beam]['true_tags'])\n",
    "model.comp_preds = beam_stats\n",
    "comp_acc = model.score_func(model.comp_preds[1]['pred_tags'], model.comp_preds[1]['true_tags'])\n",
    "model.save(manual_path='model_V{:}_E0{:}_comp_acc{:.4f}.pth'.format(model.version, model.get_log(), comp_acc))\n",
    "\n",
    "description = f\"comp_acc={comp_acc}, {len(feature_vector.feats)} feat_groups, {len(feature_vector)} total_feats\"\n",
    "logger.log(model, w0_init, create_feats, load_datasets, description, manual_cols = {'val_score': comp_acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>version</th>\n",
       "      <th>epoch</th>\n",
       "      <th>seed</th>\n",
       "      <th>init</th>\n",
       "      <th>features</th>\n",
       "      <th>datasets</th>\n",
       "      <th>train_time</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>train_score</th>\n",
       "      <th>val_score</th>\n",
       "      <th>train_aprox</th>\n",
       "      <th>val_aprox</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>beam</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.2</td>\n",
       "      <td>30</td>\n",
       "      <td>42</td>\n",
       "      <td>def w0_uniform_0_1():\\n    return np.random.ra...</td>\n",
       "      <td>def create_feats(prints=True):\\n    group_thre...</td>\n",
       "      <td>def load_datasets():\\n#     train_dataset = pr...</td>\n",
       "      <td>15.766395</td>\n",
       "      <td>08:25:04 25-04-2020</td>\n",
       "      <td>2.817186</td>\n",
       "      <td>6.461998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.923282</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>comp_acc=0.9232824275290084, 33 feat_groups, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.1</td>\n",
       "      <td>44</td>\n",
       "      <td>42</td>\n",
       "      <td>def w0_uniform_0_1():\\n    return np.random.ra...</td>\n",
       "      <td>def create_feats(prints=True):\\n    group_thre...</td>\n",
       "      <td>def load_datasets():\\n#     train_dataset = pr...</td>\n",
       "      <td>40.406914</td>\n",
       "      <td>00:32:05 25-04-2020</td>\n",
       "      <td>1.376101</td>\n",
       "      <td>6.598743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.925276</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>comp_acc=0.9252761274372981, 33 feat_groups, 4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   version  epoch  seed                                               init  \\\n",
       "1      2.2     30    42  def w0_uniform_0_1():\\n    return np.random.ra...   \n",
       "0      2.1     44    42  def w0_uniform_0_1():\\n    return np.random.ra...   \n",
       "\n",
       "                                            features  \\\n",
       "1  def create_feats(prints=True):\\n    group_thre...   \n",
       "0  def create_feats(prints=True):\\n    group_thre...   \n",
       "\n",
       "                                            datasets  train_time  \\\n",
       "1  def load_datasets():\\n#     train_dataset = pr...   15.766395   \n",
       "0  def load_datasets():\\n#     train_dataset = pr...   40.406914   \n",
       "\n",
       "             timestamp  train_loss  val_loss  train_score  val_score  \\\n",
       "1  08:25:04 25-04-2020    2.817186  6.461998          0.0   0.923282   \n",
       "0  00:32:05 25-04-2020    1.376101  6.598743          0.0   0.925276   \n",
       "\n",
       "   train_aprox  val_aprox  batch_size  weight_decay  beam  \\\n",
       "1            0          0         250           0.0     1   \n",
       "0            0          0         250           0.0     1   \n",
       "\n",
       "                                         description  \n",
       "1  comp_acc=0.9232824275290084, 33 feat_groups, 4...  \n",
       "0  comp_acc=0.9252761274372981, 33 feat_groups, 4...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(logger.leadboard(col='val_loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23674/23674 [00:33<00:00, 701.04it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.1838684549489193"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss = classifier._loss_and_grad(v=model.weights,\n",
    "                                     model=model,\n",
    "                                     epochs=0,\n",
    "                                     train_dataset=None,\n",
    "                                     val_dataset=test1_dataset,\n",
    "                                     train=False,\n",
    "                                     weight_decay=0.0,\n",
    "                                     batch_size=None,\n",
    "                                     save=False,\n",
    "                                     tqdm_bar=True,\n",
    "                                     beam=0,\n",
    "                                     train_aprox=0,\n",
    "                                     val_aprox=0,\n",
    "                                     batch_growth=None)\n",
    "val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model version: 12\n",
      "epochs: 90\n",
      "train_time: 986.882\n",
      "\n",
      "last train_loss: 1.617005\n",
      "last val_loss: 3.183868\n",
      "last train_score: 0.000000\n",
      "last val_score: 0.000000\n",
      "best val_score: 0.0000 at epoch 90\n"
     ]
    }
   ],
   "source": [
    "# best_model = classifier.load_model(from_file='model_V12_E087_comp_acc0.9247.pth')\n",
    "best_model = classifier.load_model(from_file='model_V12_E090_comp_acc0.9271.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8826363431893397,\n",
       " 0.18870710834137938,\n",
       " 0.2788713525921819,\n",
       " 0.7003578299727713,\n",
       " 0.8466611422383059]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst.append(np.random.rand())\n",
    "lst = lst[-5:]\n",
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.avg_weights(save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23579/23579 [00:33<00:00, 697.52it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.977689309380855"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss = classifier._loss_and_grad(v=model.weights,\n",
    "                                     model=model,\n",
    "                                     epochs=0,\n",
    "                                     train_dataset=None,\n",
    "                                     val_dataset=test1_dataset,\n",
    "                                     train=False,\n",
    "                                     weight_decay=0.0,\n",
    "                                     batch_size=None,\n",
    "                                     save=False,\n",
    "                                     tqdm_bar=True,\n",
    "                                     beam=0,\n",
    "                                     train_aprox=0,\n",
    "                                     val_aprox=0,\n",
    "                                     batch_growth=None)\n",
    "val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val1_dataset = preprocess.Dataset('data/test1.wtag')\n",
    "aprox_num = 1000  # max samples to aproximate score\n",
    "display_all = False\n",
    "beam_stats = {}\n",
    "dataset = val1_dataset\n",
    "# dataset = comp_dataset\n",
    "\n",
    "for predict_beam in [1]:  # viterbi beam size\n",
    "    beam_stats[predict_beam] = {}\n",
    "    beam_stats[predict_beam]['pred_tags'] = []\n",
    "    beam_stats[predict_beam]['true_tags'] = []\n",
    "    pbar = tqdm(dataset.sentences[:aprox_num])\n",
    "    for sentence in pbar:\n",
    "        preds = model(sentence[0], predict_beam)\n",
    "        beam_stats[predict_beam]['pred_tags'].append(preds)\n",
    "        beam_stats[predict_beam]['true_tags'].append(sentence[1])\n",
    "\n",
    "        if display_all:\n",
    "            display(pd.DataFrame((sentence[0], sentence[1], preds), index=('words', 'tags', 'preds')))\n",
    "        pbar.set_postfix(acc=model.score_func(beam_stats[predict_beam]['pred_tags'],\n",
    "                                              beam_stats[predict_beam]['true_tags']),\n",
    "                         refresh=False)\n",
    "\n",
    "    beam_stats[predict_beam]['matrix'], beam_stats[predict_beam]['worst'] = \\\n",
    "                                        metrics.confusion_matrix(tags,\n",
    "                                                                 beam_stats[predict_beam]['pred_tags'],\n",
    "                                                                 beam_stats[predict_beam]['true_tags'])\n",
    "# model.comp_preds = beam_stats\n",
    "model.val_preds = beam_stats\n",
    "model.save(manual_path='model_V12_E076_comp_test_preds.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.plot(['val_loss', 'train_loss'], 'loss', 'loss', scale='linear', basey=10)\n",
    "model.plot(['batch_size'], 'batch_size', 'batch_size', scale='log', basey=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = classifier.load_model(from_file='checkpoint_V11_E081_0.952_SEED42.pth')\n",
    "best_model.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NN</th>\n",
       "      <th>JJ</th>\n",
       "      <th>NNP</th>\n",
       "      <th>RB</th>\n",
       "      <th>IN</th>\n",
       "      <th>VBN</th>\n",
       "      <th>NNS</th>\n",
       "      <th>VBD</th>\n",
       "      <th>VB</th>\n",
       "      <th>VBP</th>\n",
       "      <th>...</th>\n",
       "      <th>WP</th>\n",
       "      <th>-LRB-</th>\n",
       "      <th>TO</th>\n",
       "      <th>:</th>\n",
       "      <th>-RRB-</th>\n",
       "      <th>WRB</th>\n",
       "      <th>EX</th>\n",
       "      <th>WP$</th>\n",
       "      <th>``</th>\n",
       "      <th>SYM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NN</th>\n",
       "      <td>3133</td>\n",
       "      <td>94</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JJ</th>\n",
       "      <td>112</td>\n",
       "      <td>1299</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NNP</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>1916</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RB</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>713</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IN</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2479</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VBN</th>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>431</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NNS</th>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1432</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VBD</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>791</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VB</th>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>540</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VBP</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>283</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NNPS</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VBG</th>\n",
       "      <td>26</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JJR</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VBZ</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RBR</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RP</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CD</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WDT</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JJS</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RBS</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POS</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PDT</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MD</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UH</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FW</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CC</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRP</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>''</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRP$</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WP</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-LRB-</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TO</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>524</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-RRB-</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WRB</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EX</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WP$</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>``</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SYM</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         NN    JJ   NNP   RB    IN  VBN   NNS  VBD   VB  VBP  ...  WP  -LRB-  \\\n",
       "NN     3133    94    15   11     3    5     9    3   18   12  ...   0      0   \n",
       "JJ      112  1299    23   22     1   28     1    1    7    6  ...   0      0   \n",
       "NNP      26    26  1916    0     3    0     2    0    1    0  ...   0      0   \n",
       "RB        3    12     1  713    52    0     0    0    2    1  ...   0      0   \n",
       "IN        2     1     0   18  2479    0     0    0    2    2  ...   0      0   \n",
       "VBN       0    32     0    0     0  431     0   31    0    0  ...   0      0   \n",
       "NNS      35     2     8    1     0    0  1432    0    0    0  ...   0      0   \n",
       "VBD       2     8     1    0     0   33     0  791    2    6  ...   0      0   \n",
       "VB       16     8     0    6     1    1     0    1  540   16  ...   0      0   \n",
       "VBP       7     1     0    0     0    0     0    7   11  283  ...   0      0   \n",
       "NNPS      0     0    18    0     0    0     1    0    0    0  ...   0      0   \n",
       "VBG      26    12     0    0     1    0     0    0    1    1  ...   0      0   \n",
       "JJR       2     0     0    1     1    0     0    0    1    0  ...   0      0   \n",
       "VBZ       0     0     0    0     0    0    14    0    0    1  ...   0      0   \n",
       "RBR       0     0     0    2     0    0     0    0    0    0  ...   0      0   \n",
       "DT        0     0     2    4     3    0     0    0    0    0  ...   0      0   \n",
       "RP        1     0     0    3    12    0     0    0    0    0  ...   0      0   \n",
       "CD        6     1     2    0     0    0     1    0    0    0  ...   0      0   \n",
       "WDT       0     0     0    0     4    0     0    0    0    0  ...   0      0   \n",
       "JJS       0     0     0    1     0    0     0    0    0    0  ...   0      0   \n",
       "RBS       0     0     0    0     0    0     0    0    0    0  ...   0      0   \n",
       "POS       0     0     0    0     0    0     0    0    0    0  ...   0      0   \n",
       "PDT       0     1     0    0     0    0     0    0    0    0  ...   0      0   \n",
       "#         0     0     0    0     0    0     0    0    0    0  ...   0      0   \n",
       "MD        1     0     0    0     0    0     0    0    0    0  ...   0      0   \n",
       "UH        0     0     0    0     0    0     0    0    0    0  ...   0      0   \n",
       "FW        0     0     0    0     0    0     0    0    0    0  ...   0      0   \n",
       "CC        0     0     0    2     0    0     0    0    0    0  ...   0      0   \n",
       "PRP       0     0     0    0     0    0     0    0    0    0  ...   0      0   \n",
       "''        0     0     0    0     0    0     0    0    0    0  ...   0      0   \n",
       "PRP$      0     0     0    0     0    0     1    0    0    0  ...   0      0   \n",
       "$         0     0     0    0     0    0     0    0    0    0  ...   0      0   \n",
       ".         0     0     0    0     0    0     0    0    0    0  ...   0      0   \n",
       ",         0     0     0    0     0    0     0    0    0    0  ...   0      0   \n",
       "WP        0     0     0    0     0    0     0    0    0    0  ...  52      0   \n",
       "-LRB-     0     0     0    0     0    0     0    0    0    0  ...   0     35   \n",
       "TO        0     0     0    0     0    0     0    0    0    0  ...   0      0   \n",
       ":         0     0     0    0     0    0     0    0    0    0  ...   0      0   \n",
       "-RRB-     0     0     0    0     0    0     0    0    0    0  ...   0      0   \n",
       "WRB       0     0     0    0     0    0     0    0    0    0  ...   0      0   \n",
       "EX        0     0     0    0     0    0     0    0    0    0  ...   0      0   \n",
       "WP$       0     0     0    0     0    0     0    0    0    0  ...   0      0   \n",
       "``        0     0     0    0     0    0     0    0    0    0  ...   0      0   \n",
       "SYM       0     0     0    0     0    0     0    0    0    0  ...   0      0   \n",
       "\n",
       "        TO    :  -RRB-  WRB  EX  WP$   ``  SYM  \n",
       "NN       0    0      0    0   0    0    0    0  \n",
       "JJ       0    0      0    0   0    0    0    0  \n",
       "NNP      0    0      0    0   0    0    0    0  \n",
       "RB       0    0      0    0   0    0    0    0  \n",
       "IN       0    0      0    0   0    0    0    0  \n",
       "VBN      0    0      0    0   0    0    0    0  \n",
       "NNS      0    0      0    0   0    0    0    0  \n",
       "VBD      0    0      0    0   0    0    0    0  \n",
       "VB       0    0      0    0   0    0    0    0  \n",
       "VBP      0    0      0    0   0    0    0    0  \n",
       "NNPS     0    0      0    0   0    0    0    0  \n",
       "VBG      0    0      0    0   0    0    0    0  \n",
       "JJR      0    0      0    0   0    0    0    0  \n",
       "VBZ      0    0      0    0   0    0    0    0  \n",
       "RBR      0    0      0    0   0    0    0    0  \n",
       "DT       0    0      0    0   0    0    0    0  \n",
       "RP       0    0      0    0   0    0    0    0  \n",
       "CD       0    0      0    0   0    0    0    0  \n",
       "WDT      0    0      0    0   0    0    0    0  \n",
       "JJS      0    0      0    0   0    0    0    0  \n",
       "RBS      0    0      0    0   0    0    0    0  \n",
       "POS      0    0      0    0   0    0    0    0  \n",
       "PDT      0    0      0    0   0    0    0    0  \n",
       "#        0    0      0    0   0    0    0    0  \n",
       "MD       0    0      0    0   0    0    0    0  \n",
       "UH       0    0      0    0   0    0    0    0  \n",
       "FW       0    0      0    0   0    0    0    0  \n",
       "CC       0    0      0    0   0    0    0    0  \n",
       "PRP      0    0      0    0   0    0    0    0  \n",
       "''       0    0      0    0   0    0    0    0  \n",
       "PRP$     0    0      0    0   0    0    0    0  \n",
       "$        0    0      0    0   0    0    0    0  \n",
       ".        0    0      0    0   0    0    0    0  \n",
       ",        0    0      0    0   0    0    0    0  \n",
       "WP       0    0      0    0   0    0    0    0  \n",
       "-LRB-    0    0      0    0   0    0    0    0  \n",
       "TO     524    0      0    0   0    0    0    0  \n",
       ":        0  115      0    0   0    0    0    0  \n",
       "-RRB-    0    0     35    0   0    0    0    0  \n",
       "WRB      0    0      0   56   0    0    0    0  \n",
       "EX       0    0      0    0  24    0    0    0  \n",
       "WP$      0    0      0    0   0    8    0    0  \n",
       "``       0    0      0    0   0    0  150    0  \n",
       "SYM      0    0      0    0   0    0    0    0  \n",
       "\n",
       "[44 rows x 44 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.beam_stats[1]['matrix'][worst_tags].loc[worst_tags].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NN': 0.9806116414632086,\n",
       " 'JJ': 0.9823434991974318,\n",
       " 'NNP': 0.9930725690631073,\n",
       " 'RB': 0.9935372138210695,\n",
       " 'IN': 0.9941285798766579,\n",
       " 'VBN': 0.9943397820393681,\n",
       " 'NNS': 0.9948044267973304,\n",
       " 'VBD': 0.9959871589085072,\n",
       " 'VB': 0.9960293993410493,\n",
       " 'VBP': 0.9968319675593478,\n",
       " 'NNPS': 0.9969164484244318,\n",
       " 'VBG': 0.9969586888569739,\n",
       " 'JJR': 0.9977190166427304,\n",
       " 'VBZ': 0.9980146996705246,\n",
       " 'RBR': 0.998479344428487,\n",
       " 'DT': 0.9986483061586551,\n",
       " 'RP': 0.9987750274562811,\n",
       " 'CD': 0.9991129509166173,\n",
       " 'WDT': 0.9992396722142435,\n",
       " 'JJS': 0.9993663935118695,\n",
       " 'RBS': 0.9995353552420376,\n",
       " 'POS': 0.9996620765396638,\n",
       " 'PDT': 0.9997465574047478,\n",
       " '#': 0.9997887978372898,\n",
       " 'MD': 0.9997887978372898,\n",
       " 'UH': 0.9998310382698319,\n",
       " 'FW': 0.9998732787023739,\n",
       " 'CC': 0.9998732787023739,\n",
       " 'PRP': 0.9999155191349159,\n",
       " \"''\": 0.9999155191349159,\n",
       " 'PRP$': 0.9999155191349159,\n",
       " '$': 0.9999577595674579,\n",
       " '.': 0.9999577595674579,\n",
       " ',': 1.0,\n",
       " 'WP': 1.0,\n",
       " '-LRB-': 1.0,\n",
       " 'TO': 1.0,\n",
       " ':': 1.0,\n",
       " '-RRB-': 1.0,\n",
       " 'WRB': 1.0,\n",
       " 'EX': 1.0,\n",
       " 'WP$': 1.0,\n",
       " '``': 1.0,\n",
       " 'SYM': 1.0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.beam_stats[1]['worst']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.beam_stats = beam_stats\n",
    "model.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(matrix1)\n",
    "display(matrix2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(worst1)\n",
    "display(worst2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code that may be useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences = {}\n",
    "# for sentence in train_dataset.sentences:\n",
    "#     sentences[len(sentence[0])] = sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# sample_sentence = (['Terms', 'were', \"n't\", 'disclosed', '.'],  # sentence words\n",
    "#                    ['NNS',   'VBD',  'RB',  'VBN',       '.'])  # sentence true tags\n",
    "# predict_beam = 100  # viterbi beam size\n",
    "\n",
    "# tags, bp_pi = viterbi(model, sample_sentence[0], beam=predict_beam)\n",
    "# print('sentence ', sample_sentence[0])\n",
    "# print('true tags', sample_sentence[1])\n",
    "# print('pred tags', tags)\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3802186.0\n",
      "760.4372\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32871</th>\n",
       "      <td>16939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42333</th>\n",
       "      <td>16939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42378</th>\n",
       "      <td>16939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42289</th>\n",
       "      <td>16939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42423</th>\n",
       "      <td>16939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7471</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7472</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13388</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7476</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8908</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42783 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        feat\n",
       "32871  16939\n",
       "42333  16939\n",
       "42378  16939\n",
       "42289  16939\n",
       "42423  16939\n",
       "...      ...\n",
       "7471       1\n",
       "7472       1\n",
       "13388      1\n",
       "7476       1\n",
       "8908       1\n",
       "\n",
       "[42783 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.2 s, sys: 15.6 ms, total: 28.3 s\n",
      "Wall time: 28.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sum_vec = np.zeros(len(feature_vector)).astype(np.float32)\n",
    "sum_inds = 0\n",
    "for t2, t1, w, i, t in train_dataset:\n",
    "    vec = feature_vector(t2, t1, w, i, t, fmt='vec')\n",
    "    sum_vec += vec\n",
    "    sum_inds += (vec).sum()\n",
    "\n",
    "df = pd.DataFrame(sum_vec, columns=['feat']).astype({'feat': int}).sort_values('feat', ascending=False)\n",
    "print(sum_vec.sum())\n",
    "print(sum_inds/len(train_dataset.sentences))\n",
    "display(df.head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17008</th>\n",
       "      <td>6199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19968</th>\n",
       "      <td>6199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42480</th>\n",
       "      <td>6044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24990</th>\n",
       "      <td>6044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19758</th>\n",
       "      <td>6044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20012</th>\n",
       "      <td>6044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>6044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26421</th>\n",
       "      <td>6044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42299</th>\n",
       "      <td>6044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42179</th>\n",
       "      <td>6044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32881</th>\n",
       "      <td>6044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22556</th>\n",
       "      <td>6044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42388</th>\n",
       "      <td>6044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33000</th>\n",
       "      <td>6044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32927</th>\n",
       "      <td>6044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17056</th>\n",
       "      <td>6044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42433</th>\n",
       "      <td>6044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42667</th>\n",
       "      <td>6044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18812</th>\n",
       "      <td>6044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42239</th>\n",
       "      <td>6044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14771</th>\n",
       "      <td>6044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42611</th>\n",
       "      <td>6044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42735</th>\n",
       "      <td>6044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42343</th>\n",
       "      <td>6044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42554</th>\n",
       "      <td>6044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42655</th>\n",
       "      <td>5104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42606</th>\n",
       "      <td>4962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42383</th>\n",
       "      <td>4962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42174</th>\n",
       "      <td>4962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32921</th>\n",
       "      <td>4962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42294</th>\n",
       "      <td>4962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42549</th>\n",
       "      <td>4962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32995</th>\n",
       "      <td>4962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42474</th>\n",
       "      <td>4962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42662</th>\n",
       "      <td>4962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32876</th>\n",
       "      <td>4962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42234</th>\n",
       "      <td>4962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42428</th>\n",
       "      <td>4962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42728</th>\n",
       "      <td>4962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42338</th>\n",
       "      <td>4962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31974</th>\n",
       "      <td>4934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18787</th>\n",
       "      <td>4914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14742</th>\n",
       "      <td>4914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19740</th>\n",
       "      <td>4914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24962</th>\n",
       "      <td>4914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19988</th>\n",
       "      <td>4914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17030</th>\n",
       "      <td>4914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22530</th>\n",
       "      <td>4914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feat\n",
       "0      6199\n",
       "17008  6199\n",
       "19968  6199\n",
       "42480  6044\n",
       "24990  6044\n",
       "19758  6044\n",
       "20012  6044\n",
       "56     6044\n",
       "26421  6044\n",
       "42299  6044\n",
       "42179  6044\n",
       "32881  6044\n",
       "22556  6044\n",
       "42388  6044\n",
       "33000  6044\n",
       "32927  6044\n",
       "17056  6044\n",
       "42433  6044\n",
       "42667  6044\n",
       "18812  6044\n",
       "42239  6044\n",
       "14771  6044\n",
       "42611  6044\n",
       "42735  6044\n",
       "42343  6044\n",
       "42554  6044\n",
       "42655  5104\n",
       "42606  4962\n",
       "42383  4962\n",
       "42174  4962\n",
       "32921  4962\n",
       "42294  4962\n",
       "42549  4962\n",
       "32995  4962\n",
       "42474  4962\n",
       "42662  4962\n",
       "32876  4962\n",
       "42234  4962\n",
       "42428  4962\n",
       "42728  4962\n",
       "42338  4962\n",
       "31974  4934\n",
       "18787  4914\n",
       "14742  4914\n",
       "19740  4914\n",
       "24962  4914\n",
       "23     4914\n",
       "19988  4914\n",
       "17030  4914\n",
       "22530  4914"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.loc[0:100].head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeatureGroup(tuple([w[i].lower(), t]))\n",
      "('low-density', 'NN')\n"
     ]
    }
   ],
   "source": [
    "feat, key = feature_vector.invert_feat(4914)  # 41453 22811\n",
    "print(feat)\n",
    "print(key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test run train_dataset\n",
    "# tic = time.time()\n",
    "# for t2, t1, w, i, t in train_dataset:\n",
    "#     feat_vec_t = feature_vector(t2, t1, w, i, t, fmt='vec')\n",
    "# print('fmt=vec: {:.3f} sec'.format(time.time() - tic))\n",
    "\n",
    "# tic = time.time()\n",
    "# for t2, t1, w, i, t in train_dataset:\n",
    "#     feat_list_t = feature_vector(t2, t1, w, i, t, fmt='list')\n",
    "# print('fmt=list: {:.3f} sec'.format(time.time() - tic))\n",
    "\n",
    "# tic = time.time()\n",
    "# for t2, t1, w, i, t in train_dataset:\n",
    "#     feat_vec_t, feat_list_t = feature_vector(t2, t1, w, i, t, fmt='both')\n",
    "# print('fmt=vec+list: {:.3f} sec'.format(time.time() - tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tag in train1_statistics.words_per_tag:\n",
    "#     if len(train1_statistics.words_per_tag[tag]) < 10:\n",
    "#         print('{:5} tf: {:5d} unique_count: {:4d} words: {}'.format(tag, train1_statistics.tags_count[tag], len(train1_statistics.words_per_tag[tag]),\n",
    "#                                                                     train1_statistics.words_per_tag[tag]))\n",
    "#     else:\n",
    "#         print('{:5} tf: {:5d} unique_count: {:4d}'.format(tag, train1_statistics.tags_count[tag], len(train1_statistics.words_per_tag[tag])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = []\n",
    "\n",
    "# # one-to-one features\n",
    "# for word in strange_words:\n",
    "#     features.append(Feature(f'w[i] == \"{word}\"', t=train1_model.tags_per_word[word][0]))\n",
    "#     print(word, train1_model.WordCount[word], train1_model.TagsPerWord[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_hw1",
   "language": "python",
   "name": "nlp_hw1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
