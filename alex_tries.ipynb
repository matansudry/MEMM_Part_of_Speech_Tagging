{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import scipy\n",
    "# from scipy import optimize\n",
    "from utils import preprocess, score, features\n",
    "from utils.features import prefix, suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params, maybe need to remove that\n",
    "model_name = 'model.pickle'\n",
    "model_matrices = 'model_matrices.pickle'\n",
    "model_preprocess = 'model_preprocess.pickle'\n",
    "load_model = False\n",
    "load_matrices = False\n",
    "load_preprocess = False\n",
    "verbose = 1\n",
    "\n",
    "# variables\n",
    "limit_common_words = 5\n",
    "threshold = 0\n",
    "args = None\n",
    "lamda = 0.1\n",
    "\n",
    "# data files\n",
    "comp1_path = 'data/comp1.words'\n",
    "comp2_path = 'data/comp2.words'\n",
    "test1_path = 'data/test1.wtag'\n",
    "train1_path = 'data/train1.wtag'\n",
    "train2_path = 'data/train2.wtag'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# train1_statistics = preprocess.feature_statistics_class(train1_path, limit_common_words, lamda)\n",
    "# train1_statistics.get_statistics()\n",
    "# train2_statistics = preprocess.feature_statistics_class(train2_path, limit_common_words, lamda)\n",
    "# train2_statistics.get_statistics()\n",
    "# id_class = preprocess.feature2id_class(train1_statistics, threshold)\n",
    "# id_class.get_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_tags = set(train1_statistics.tags)\n",
    "# tags_dict = dict(zip(all_tags, range(len(all_tags))))\n",
    "# display(tags_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create FeatureGroup params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_groups_dicts = {\n",
    "    ('t2', 't1', 't'): dict(),\n",
    "    ('t1', 't'): dict(),\n",
    "    ('w[i]', 't'): dict(),\n",
    "    ('w[i-1]', 't'): dict(),\n",
    "    ('w[i+1]', 't'): dict(),\n",
    "    ('prefix(w[i], 3)', 't'): dict(),\n",
    "    ('prefix(w[i], 2)', 't'): dict(),\n",
    "    ('prefix(w[i+1], 3)', 't'): dict(),\n",
    "    ('prefix(w[i-1], 3)', 't'): dict(),\n",
    "    ('suffix(w[i], 3)', 't'): dict(),\n",
    "    ('suffix(w[i], 2)', 't'): dict(),\n",
    "    ('suffix(w[i+1], 3)', 't'): dict(),\n",
    "    ('suffix(w[i-1], 3)', 't'): dict(),\n",
    "\n",
    "}\n",
    "\n",
    "single_features_list = [\n",
    "    'w[i] == w[i].lower()',\n",
    "    'any(char.isdigit() for char in w[i])',\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_group: FeatureGroup(('t2', 't1', 't'), dict(...)) | feats: 8150\n",
      "feat_group: FeatureGroup(('t1', 't'), dict(...)) | feats: 1060\n",
      "feat_group: FeatureGroup(('w[i]', 't'), dict(...)) | feats: 15415\n",
      "feat_group: FeatureGroup(('w[i-1]', 't'), dict(...)) | feats: 32170\n",
      "feat_group: FeatureGroup(('w[i+1]', 't'), dict(...)) | feats: 30777\n",
      "feat_group: FeatureGroup(('prefix(w[i], 3)', 't'), dict(...)) | feats: 8061\n",
      "feat_group: FeatureGroup(('prefix(w[i], 2)', 't'), dict(...)) | feats: 3009\n",
      "feat_group: FeatureGroup(('prefix(w[i+1], 3)', 't'), dict(...)) | feats: 17800\n",
      "feat_group: FeatureGroup(('prefix(w[i-1], 3)', 't'), dict(...)) | feats: 18458\n",
      "feat_group: FeatureGroup(('suffix(w[i], 3)', 't'), dict(...)) | feats: 4500\n",
      "feat_group: FeatureGroup(('suffix(w[i], 2)', 't'), dict(...)) | feats: 1659\n",
      "feat_group: FeatureGroup(('suffix(w[i+1], 3)', 't'), dict(...)) | feats: 13488\n",
      "feat_group: FeatureGroup(('suffix(w[i-1], 3)', 't'), dict(...)) | feats: 13844\n",
      "feat_group: Feature(('w[i] == w[i].lower()',)) | feats: 1\n",
      "feat_group: Feature(('any(char.isdigit() for char in w[i])',)) | feats: 1\n",
      "feat_groups: 15 | total_feats: 168393\n",
      "CPU times: user 1min 4s, sys: 8.47 s, total: 1min 13s\n",
      "Wall time: 1min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get statistics\n",
    "train1_statistics = preprocess.feature_statistics_class(train1_path, limit_common_words, lamda)\n",
    "train1_statistics.get_statistics()\n",
    "\n",
    "\n",
    "for sentence in range(len(train1_statistics.sentences_with_only_word)):\n",
    "    w = train1_statistics.sentences_with_only_word[sentence]\n",
    "    tags = train1_statistics.sentences_with_only_tag[sentence]\n",
    "    t1 = '*'\n",
    "    t = '*'\n",
    "    for i in range(len(w)):\n",
    "        t2, t1, t = t1, t, tags[i]\n",
    "        for hash_rule in feature_groups_dicts:\n",
    "            try:\n",
    "                key = tuple(eval(r) for r in hash_rule)\n",
    "                if key not in feature_groups_dicts[hash_rule]:\n",
    "                    feature_groups_dicts[hash_rule][key] = 1\n",
    "                else:\n",
    "                    feature_groups_dicts[hash_rule][key] += 1\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "# init FeatureGroups and Features\n",
    "features_list = []\n",
    "for hash_rule in feature_groups_dicts:\n",
    "    features_list.append(features.FeatureGroup(hash_rule, feature_groups_dicts[hash_rule]))\n",
    "    \n",
    "for feat in single_features_list:\n",
    "    features_list.append(features.Feature(feat))\n",
    "    \n",
    "# init FeatureVector\n",
    "feature_vector = features.FeatureVector(features_list)\n",
    "\n",
    "# display statistics\n",
    "total_feats = 0\n",
    "for feat in features_list:\n",
    "    feat_len = len(feat)\n",
    "    total_feats += feat_len\n",
    "    print('feat_group:', feat, '| feats:', feat_len)\n",
    "print('feat_groups:', len(features_list), '| total_feats:', total_feats)\n",
    "assert len(feature_vector) == total_feats"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "feat_group: FeatureGroup(('t2', 't1', 't'), dict(...)) | feats: 8150\n",
    "feat_group: FeatureGroup(('t1', 't'), dict(...)) | feats: 1060\n",
    "feat_group: FeatureGroup(('w[i]', 't'), dict(...)) | feats: 15415\n",
    "feat_group: FeatureGroup(('w[i-1]', 't'), dict(...)) | feats: 32170\n",
    "feat_group: FeatureGroup(('w[i+1]', 't'), dict(...)) | feats: 30777\n",
    "feat_group: FeatureGroup(('prefix(w[i], 3)', 't'), dict(...)) | feats: 8061\n",
    "feat_group: FeatureGroup(('prefix(w[i], 2)', 't'), dict(...)) | feats: 3009\n",
    "feat_group: FeatureGroup(('prefix(w[i+1], 3)', 't'), dict(...)) | feats: 17800\n",
    "feat_group: FeatureGroup(('prefix(w[i-1], 3)', 't'), dict(...)) | feats: 18458\n",
    "feat_group: FeatureGroup(('suffix(w[i], 3)', 't'), dict(...)) | feats: 4500\n",
    "feat_group: FeatureGroup(('suffix(w[i], 2)', 't'), dict(...)) | feats: 1659\n",
    "feat_group: FeatureGroup(('suffix(w[i+1], 3)', 't'), dict(...)) | feats: 13488\n",
    "feat_group: FeatureGroup(('suffix(w[i-1], 3)', 't'), dict(...)) | feats: 13844\n",
    "feat_group: Feature(('w[i] == w[i].lower()',)) | feats: 1\n",
    "feat_group: Feature(('any(char.isdigit() for char in w[i])',)) | feats: 1\n",
    "feat_groups: 15 | total_feats: 168393"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". 4914 ['.']\n",
      "`` 838 ['``']\n",
      ", 6044 [',']\n",
      "'' 813 [\"''\"]\n",
      "$ 773 ['$']\n",
      "-- 256 [':']\n",
      "-LRB- 148 ['-LRB-']\n",
      "-RRB- 148 ['-RRB-']\n",
      ": 149 [':']\n",
      "-LCB- 30 ['-LRB-']\n",
      "-RCB- 30 ['-RRB-']\n",
      "; 133 [':']\n",
      "... 19 [':']\n",
      "C$ 13 ['$']\n",
      "US$ 15 ['$']\n",
      "A$ 1 ['$']\n",
      "? 43 ['.']\n",
      "! 5 ['.']\n",
      "` 8 ['``']\n",
      "- 8 [':']\n",
      "# 7 ['#']\n",
      "HK$ 6 ['$']\n"
     ]
    }
   ],
   "source": [
    "# features = []\n",
    "\n",
    "# # one-to-one features\n",
    "# for word in strange_words:\n",
    "#     features.append(Feature(f'w[i] == \"{word}\"', t=train1_model.TagsPerWord[word][0]))\n",
    "#     print(word, train1_model.WordCount[word], train1_model.TagsPerWord[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "t2, t1, w, i, t = 'NN', 'VB', ['preprocessing' for _ in range(200)], 100, 'NN'\n",
    "print(feat(t2, t1, w, i, t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_hw1",
   "language": "python",
   "name": "nlp_hw1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
