{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "from scipy import optimize\n",
    "from utils import preprocess, score, features, classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params, maybe need to remove that\n",
    "model_name = 'model.pickle'\n",
    "model_matrices = 'model_matrices.pickle'\n",
    "model_preprocess = 'model_preprocess.pickle'\n",
    "load_model = False\n",
    "load_matrices = False\n",
    "load_preprocess = False\n",
    "verbose = 1\n",
    "\n",
    "# variables\n",
    "limit_common_words = 5\n",
    "threshold = 0\n",
    "args = None\n",
    "lamda = 0.1\n",
    "\n",
    "# data files\n",
    "comp1_path = 'data/comp1.words'\n",
    "comp2_path = 'data/comp2.words'\n",
    "test1_path = 'data/test1.wtag'\n",
    "train1_path = 'data/train1.wtag'\n",
    "train2_path = 'data/train2.wtag'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create FeatureGroup params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_thresholds = {\n",
    "    lambda t2, t1, w, i, t: tuple([t2, t1, t]):                               1,\n",
    "    lambda t2, t1, w, i, t: tuple([t1, t]):                                   1,\n",
    "    lambda t2, t1, w, i, t: tuple([w[i].lower(), t]):                         None,\n",
    "#     lambda t2, t1, w, i, t: tuple([w[i-1].lower(), t]):                       5,\n",
    "#     lambda t2, t1, w, i, t: tuple([w[i+1].lower(), t]):                       5,\n",
    "    lambda t2, t1, w, i, t: tuple([w[i][:3].lower(), t]):                     5,\n",
    "    lambda t2, t1, w, i, t: tuple([w[i][:2].lower(), t]):                     5,\n",
    "#     lambda t2, t1, w, i, t: tuple([w[i+1][:3].lower(), t]):                   5,\n",
    "#     lambda t2, t1, w, i, t: tuple([w[i-1][:3].lower(), t]):                   5,\n",
    "    lambda t2, t1, w, i, t: tuple([w[i][-3:].lower(), t]):                    5,\n",
    "    lambda t2, t1, w, i, t: tuple([w[i][-2:].lower(), t]):                    5,\n",
    "#     lambda t2, t1, w, i, t: tuple([w[i+1][-3:].lower(), t]):                  5,\n",
    "#     lambda t2, t1, w, i, t: tuple([w[i-1][-3:].lower(), t]):                  5,\n",
    "    lambda t2, t1, w, i, t: tuple([w[i].isalnum(), t]):                       1,\n",
    "    lambda t2, t1, w, i, t: tuple([w[i].isalpha(), t]):                       1,\n",
    "    lambda t2, t1, w, i, t: tuple([w[i].isascii(), t]):                       1,\n",
    "    lambda t2, t1, w, i, t: tuple([w[i].isdecimal(), t]):                     1,\n",
    "    lambda t2, t1, w, i, t: tuple([w[i].isdigit(), t]):                       1,\n",
    "    lambda t2, t1, w, i, t: tuple([w[i].islower(), t]):                       1,\n",
    "    lambda t2, t1, w, i, t: tuple([w[i].isnumeric(), t]):                     1,\n",
    "    lambda t2, t1, w, i, t: tuple([w[i].istitle(), t]):                       1,\n",
    "    lambda t2, t1, w, i, t: tuple([w[i].isupper(), t]):                       1,\n",
    "    lambda t2, t1, w, i, t: tuple([len(w[i]) == 1, t]):                       1,\n",
    "    lambda t2, t1, w, i, t: tuple([len(w[i]) == 2, t]):                       1,\n",
    "    lambda t2, t1, w, i, t: tuple([len(w[i]) == 3, t]):                       1,\n",
    "    lambda t2, t1, w, i, t: tuple([w[i][0].islower(), t]):                    1,\n",
    "    lambda t2, t1, w, i, t: tuple([any(char.isdigit() for char in w[i]), t]): 1,\n",
    "    lambda t2, t1, w, i, t: tuple([any(char.isupper() for char in w[i]), t]): 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.77 s, sys: 31.2 ms, total: 3.8 s\n",
      "Wall time: 3.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dataset = preprocess.Dataset(train1_path)\n",
    "feature_vector = features.create_feature_vector(dataset, group_thresholds=group_thresholds, pruning=True, get_stats=False, assertions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_group: FeatureGroup(tuple([t2, t1, t])) | feats: 5192\n",
      "feat_group: FeatureGroup(tuple([t1, t])) | feats: 908\n",
      "feat_group: FeatureGroup(tuple([w[i].lower(), t])) | feats: 14719\n",
      "feat_group: FeatureGroup(tuple([w[i][:3].lower(), t])) | feats: 2431\n",
      "feat_group: FeatureGroup(tuple([w[i][:2].lower(), t])) | feats: 1432\n",
      "feat_group: FeatureGroup(tuple([w[i][-3:].lower(), t])) | feats: 1757\n",
      "feat_group: FeatureGroup(tuple([w[i][-2:].lower(), t])) | feats: 955\n",
      "feat_group: FeatureGroup(tuple([w[i].isalnum(), t])) | feats: 60\n",
      "feat_group: FeatureGroup(tuple([w[i].isalpha(), t])) | feats: 60\n",
      "feat_group: FeatureGroup(tuple([w[i].isascii(), t])) | feats: 44\n",
      "feat_group: FeatureGroup(tuple([w[i].isdecimal(), t])) | feats: 45\n",
      "feat_group: FeatureGroup(tuple([w[i].isdigit(), t])) | feats: 45\n",
      "feat_group: FeatureGroup(tuple([w[i].islower(), t])) | feats: 75\n",
      "feat_group: FeatureGroup(tuple([w[i].isnumeric(), t])) | feats: 45\n",
      "feat_group: FeatureGroup(tuple([w[i].istitle(), t])) | feats: 76\n",
      "feat_group: FeatureGroup(tuple([w[i].isupper(), t])) | feats: 56\n",
      "feat_group: FeatureGroup(tuple([len(w[i]) == 1, t])) | feats: 56\n",
      "feat_group: FeatureGroup(tuple([len(w[i]) == 2, t])) | feats: 66\n",
      "feat_group: FeatureGroup(tuple([len(w[i]) == 3, t])) | feats: 69\n",
      "feat_group: FeatureGroup(tuple([w[i][0].islower(), t])) | feats: 74\n",
      "feat_group: FeatureGroup(tuple([any(char.isdigit() for char in w[i]), t])) | feats: 49\n",
      "feat_group: FeatureGroup(tuple([any(char.isupper() for char in w[i]), t])) | feats: 75\n",
      "feat_groups: 22 | total_feats: 28289\n"
     ]
    }
   ],
   "source": [
    "for feat in feature_vector.feats:\n",
    "    print('feat_group:', feat, '| feats:', len(feat))\n",
    "print('feat_groups:', len(feature_vector.feats), '| total_feats:', len(feature_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fmt=vec: 6.546 sec\n",
      "fmt=list: 4.867 sec\n",
      "fmt=vec+list: 7.496 sec\n"
     ]
    }
   ],
   "source": [
    "# test run dataset\n",
    "tic = time.time()\n",
    "for t2, t1, w, i, t in dataset:\n",
    "    feat_vec_t = feature_vector(t2, t1, w, i, t, fmt='vec')\n",
    "print('fmt=vec: {:.3f} sec'.format(time.time() - tic))\n",
    "\n",
    "tic = time.time()\n",
    "for t2, t1, w, i, t in dataset:\n",
    "    feat_list_t = feature_vector(t2, t1, w, i, t, fmt='list')\n",
    "print('fmt=list: {:.3f} sec'.format(time.time() - tic))\n",
    "\n",
    "tic = time.time()\n",
    "for t2, t1, w, i, t in dataset:\n",
    "    feat_vec_t, feat_list_t = feature_vector(t2, t1, w, i, t, fmt='both')\n",
    "print('fmt=vec+list: {:.3f} sec'.format(time.time() - tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0 = np.random.rand(len(feature_vector)).astype(np.float32)/30\n",
    "seed = 42\n",
    "models_path = None\n",
    "save = False\n",
    "\n",
    "model = classifier.Model(w0=w0,\n",
    "                         tags=dataset.tags,\n",
    "                         feature_vector=feature_vector,\n",
    "                         seed=seed,\n",
    "                         score_func=score.accuracy,\n",
    "                         models_path=models_path,\n",
    "                         save=save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 5967/6236 [00:13<00:00, 447.87it/s]\n",
      "  0%|          | 1/6236 [00:00<00:21, 284.28it/s]\n"
     ]
    },
    {
     "ename": "OverflowError",
     "evalue": "math range error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d2a6bb83dc5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0miprint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             tqdm_bar=True)\n\u001b[0m",
      "\u001b[0;32m/mnt/c/Users/alexz/OneDrive/MainEnv/nlp/MEMM_Part_of_Speech_Tagging/utils/classifier.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, train_dataset, val_dataset, batch_size, weight_decay, iprint, save, tqdm_bar)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstart_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miprint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtqdm_bar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mval_dataset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miprint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtqdm_bar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/alexz/OneDrive/MainEnv/nlp/MEMM_Part_of_Speech_Tagging/utils/classifier.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, dataset, batch_size, weight_decay, iprint, tqdm_bar, train, epochs)\u001b[0m\n\u001b[1;32m     90\u001b[0m                                                                      tqdm_bar),\n\u001b[1;32m     91\u001b[0m                                                                \u001b[0mmaxiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                                                                iprint=iprint)\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             loss = loss_and_grad(v=self.weights,\n",
      "\u001b[0;32m~/.miniconda3/envs/nlp_hw1/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfmin_l_bfgs_b\u001b[0;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     res = _minimize_lbfgsb(fun, x0, args=args, jac=jac, bounds=bounds,\n\u001b[0;32m--> 199\u001b[0;31m                            **opts)\n\u001b[0m\u001b[1;32m    200\u001b[0m     d = {'grad': res['jac'],\n\u001b[1;32m    201\u001b[0m          \u001b[0;34m'task'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'message'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/nlp_hw1/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/nlp_hw1/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/nlp_hw1/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/nlp_hw1/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/alexz/OneDrive/MainEnv/nlp/MEMM_Part_of_Speech_Tagging/utils/classifier.py\u001b[0m in \u001b[0;36mloss_and_grad\u001b[0;34m(v, dataset, feature_vector, weight_decay, loss_only, batch_size, shuffle, seed, tqdm_bar)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0;31m# grad expected_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0mexp_mult_v_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse_mult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat_list_tag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mloss_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m                 \u001b[0mexpected_count_nominator_vec\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfeat_vec_tag\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mexp_mult_v_feat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOverflowError\u001b[0m: math range error"
     ]
    }
   ],
   "source": [
    "model.train(epochs=1,\n",
    "            train_dataset=dataset,\n",
    "            val_dataset=None,\n",
    "            batch_size=256,\n",
    "            weight_decay=0.0,\n",
    "            iprint=-1,\n",
    "            save=False,\n",
    "            tqdm_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.random.rand(len(feature_vector)).astype(np.float32)/30\n",
    "weight_decay = 1e2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def foo(x):\n",
    "#     return x**2, 2*x\n",
    "\n",
    "# x0 = 100\n",
    "# v_min, f_min, d_min = optimize.fmin_l_bfgs_b(func=foo, x0=x0, maxiter=10, iprint=100)\n",
    "# print(v_min, f_min, d_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121815/121815 [05:07<00:00, 396.46it/s]\n"
     ]
    }
   ],
   "source": [
    "# test run loss_and_grad\n",
    "# tic = time.time()\n",
    "loss = classifier.loss_and_grad(v, dataset, feature_vector, weight_decay, loss_only=False, batch_size=None, shuffle=True, seed=42, tqdm_bar=True)\n",
    "# print('loss={:.5f}, grad={:.5f}: {:.3f} sec'.format(loss, grad, time.time() - tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3288it [00:08, 395.85it/s]                          \n"
     ]
    }
   ],
   "source": [
    "loss, grad = classifier.loss_and_grad(v, dataset, feature_vector, weight_decay, loss_only=False, batch_size=128, shuffle=True, seed=42, tqdm_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "462420.57053219556"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.4995125e+01, -5.9916358e+00,  1.0795711e-03, ...,\n",
       "        1.8605659e-02,  6.9600726e-03,  3.2265317e-02], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121815/121815 [04:48<00:00, 422.06it/s]\n",
      "100%|██████████| 121815/121815 [04:48<00:00, 422.59it/s]\n",
      "100%|██████████| 121815/121815 [07:52<00:00, 258.06it/s]\n",
      "100%|██████████| 121815/121815 [10:24<00:00, 194.93it/s]\n",
      "100%|██████████| 121815/121815 [10:16<00:00, 197.57it/s]\n",
      "100%|██████████| 121815/121815 [11:32<00:00, 175.96it/s]\n",
      "100%|██████████| 121815/121815 [12:26<00:00, 163.20it/s]\n",
      "100%|██████████| 121815/121815 [16:12<00:00, 125.31it/s]\n",
      "100%|██████████| 121815/121815 [06:22<00:00, 318.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 24min 14s, sys: 52.4 s, total: 1h 25min 6s\n",
      "Wall time: 1h 24min 44s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "v = np.random.rand(len(feature_vector)).astype(np.float32)/30\n",
    "weight_decay = 1e6\n",
    "v_min, f_min, d_min = optimize.fmin_l_bfgs_b(func=classifier.loss_and_grad,\n",
    "                                             x0=v,\n",
    "                                             args=(dataset,\n",
    "                                                   feature_vector,\n",
    "                                                   weight_decay,\n",
    "                                                   False, # loss_only\n",
    "                                                   None,  # batch_size\n",
    "                                                   True, # shuffle\n",
    "                                                   42, # seed\n",
    "                                                   True), # tqdm_bar\n",
    "                                             maxiter=5,\n",
    "                                             iprint=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01296869, 0.0020813 , 0.00721218, ..., 0.00198896, 0.01266094,\n",
       "       0.01284344])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "393381.3427747049"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            loss_and_grad(v=self.weights,\n",
    "                          dataset=dataset,\n",
    "                          feature_vector=self.feature_vector,\n",
    "                          weight_decay=weight_decay,\n",
    "                          loss_only=True,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=False,\n",
    "                          seed=self.seed,\n",
    "                          tqdm_bar=tqdm_bar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-23659955.01495881"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1134.,  137.,   37., ...,    0.,    0.,    0.], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1), (2, 2), (3, 3), (4, 4), (5, 5), (6, 6), (7, 7), (8, 8), (9, 9)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1 = [1,2,3,4,5,6,7,8,9]\n",
    "list2 = [1,2,3,4,5,6,7,8,9]\n",
    "list3 = list(zip(list1, list2))\n",
    "list3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 7, 6, 2, 5, 9, 4, 8, 3]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1 = [1,2,3,4,5,6,7,8,9]\n",
    "n = len(list1)\n",
    "random.shuffle(list1)\n",
    "list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list1 []\n",
      "pop [1, 7, 6, 2, 5, 9, 4, 8, 3]\n"
     ]
    }
   ],
   "source": [
    "pop = list1[:n]\n",
    "del list1[:n]\n",
    "print('list1', list1)\n",
    "print('pop', pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 1]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 3, 6, 4, 7, 8, 2]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# for ix in dataset:\n",
    "#     for h in dataset.sentence(ix):\n",
    "#         _ = feature_vector(*h)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "feat_group: FeatureGroup(tuple([t2, t1, t])) | feats: 5192\n",
    "feat_group: FeatureGroup(tuple([t1, t])) | feats: 908\n",
    "feat_group: FeatureGroup(tuple([w[i].lower(), t])) | feats: 14719\n",
    "feat_group: FeatureGroup(tuple([w[i-1].lower(), t])) | feats: 2641\n",
    "feat_group: FeatureGroup(tuple([w[i+1].lower(), t])) | feats: 2631\n",
    "feat_group: FeatureGroup(tuple([w[i][:3].lower(), t])) | feats: 2431\n",
    "feat_group: FeatureGroup(tuple([w[i][:2].lower(), t])) | feats: 1432\n",
    "feat_group: FeatureGroup(tuple([w[i+1][:3].lower(), t])) | feats: 3291\n",
    "feat_group: FeatureGroup(tuple([w[i-1][:3].lower(), t])) | feats: 3396\n",
    "feat_group: FeatureGroup(tuple([w[i][-3:].lower(), t])) | feats: 1757\n",
    "feat_group: FeatureGroup(tuple([w[i][-2:].lower(), t])) | feats: 955\n",
    "feat_group: FeatureGroup(tuple([w[i+1][-3:].lower(), t])) | feats: 3195\n",
    "feat_group: FeatureGroup(tuple([w[i-1][-3:].lower(), t])) | feats: 3146\n",
    "feat_group: FeatureGroup(tuple([w[i].isalnum(), t])) | feats: 60\n",
    "feat_group: FeatureGroup(tuple([w[i].isalpha(), t])) | feats: 60\n",
    "feat_group: FeatureGroup(tuple([w[i].isascii(), t])) | feats: 44\n",
    "feat_group: FeatureGroup(tuple([w[i].isdecimal(), t])) | feats: 45\n",
    "feat_group: FeatureGroup(tuple([w[i].isdigit(), t])) | feats: 45\n",
    "feat_group: FeatureGroup(tuple([w[i].islower(), t])) | feats: 75\n",
    "feat_group: FeatureGroup(tuple([w[i].isnumeric(), t])) | feats: 45\n",
    "feat_group: FeatureGroup(tuple([w[i].istitle(), t])) | feats: 76\n",
    "feat_group: FeatureGroup(tuple([w[i].isupper(), t])) | feats: 56\n",
    "feat_group: FeatureGroup(tuple([len(w[i]) == 1, t])) | feats: 56\n",
    "feat_group: FeatureGroup(tuple([len(w[i]) == 2, t])) | feats: 66\n",
    "feat_group: FeatureGroup(tuple([len(w[i]) == 3, t])) | feats: 69\n",
    "feat_group: FeatureGroup(tuple([w[i][0].islower(), t])) | feats: 74\n",
    "feat_group: FeatureGroup(tuple([any(char.isdigit() for char in w[i]), t])) | feats: 49\n",
    "feat_group: FeatureGroup(tuple([any(char.isupper() for char in w[i]), t])) | feats: 75\n",
    "feat_groups: 28 | total_feats: 46589"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tag in train1_statistics.words_per_tag:\n",
    "#     if len(train1_statistics.words_per_tag[tag]) < 10:\n",
    "#         print('{:5} tf: {:5d} unique_count: {:4d} words: {}'.format(tag, train1_statistics.tags_count[tag], len(train1_statistics.words_per_tag[tag]),\n",
    "#                                                                     train1_statistics.words_per_tag[tag]))\n",
    "#     else:\n",
    "#         print('{:5} tf: {:5d} unique_count: {:4d}'.format(tag, train1_statistics.tags_count[tag], len(train1_statistics.words_per_tag[tag])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = []\n",
    "\n",
    "# # one-to-one features\n",
    "# for word in strange_words:\n",
    "#     features.append(Feature(f'w[i] == \"{word}\"', t=train1_model.tags_per_word[word][0]))\n",
    "#     print(word, train1_model.WordCount[word], train1_model.TagsPerWord[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "t2, t1, w, i, t = 'NN', 'VB', ['preprocessing' for _ in range(200)], 100, 'NN'\n",
    "print(feat(t2, t1, w, i, t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_hw1",
   "language": "python",
   "name": "nlp_hw1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
