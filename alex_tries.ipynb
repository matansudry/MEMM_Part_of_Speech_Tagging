{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "# from scipy.optimize import minimize\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "from utils.preprocess import feature_statistics_class, feature2id_class, Test_tagger, separate_tag_from_word, common_words\n",
    "from utils.score import accuracy, top_k_erros, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params, maybe need to remove that\n",
    "model_name = 'model.pickle'\n",
    "model_matrices = 'model_matrices.pickle'\n",
    "model_preprocess = 'model_preprocess.pickle'\n",
    "load_model = False\n",
    "load_matrices = False\n",
    "load_preprocess = False\n",
    "verbose = 1\n",
    "\n",
    "# variables\n",
    "number_of_features = 16 # need to keep this variable update\n",
    "limit_common_words = 5\n",
    "\n",
    "# data files\n",
    "comp1_path = 'data/comp1.words'\n",
    "comp2_path = 'data/comp2.words'\n",
    "test1_path = 'data/test1.wtag'\n",
    "train1_path = 'data/train1.wtag'\n",
    "train2_path = 'data/train2.wtag'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1_model = feature_statistics_class(train1, limit_common_words)\n",
    "train1_model.get_statistics()\n",
    "id_class = feature2id_class(train1_model, threshold)\n",
    "id_class.get_features()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1_model = feature_statistics_class(train1_path, limit_common_words)\n",
    "train2_model = feature_statistics_class(train2_path, limit_common_words)\n",
    "test_model = feature_statistics_class(test1_path, limit_common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'JJS', 'NN', 'WRB', 'VBN', 'LS', 'WP', 'WDT', '*', 'RBS', 'SYM', 'PRP', 'NNPS', 'DT', 'JJ', 'PRP$', 'RBR', 'CD', 'VB', 'NNS', 'RP', 'VBD', 'RB', 'VBZ', 'EX', 'MD', 'VBP', 'NNP', 'JJR', 'FW', 'WP$', 'POS', 'VBG', 'PDT', 'CC'}\n"
     ]
    }
   ],
   "source": [
    "all_tags = set(train1_model.tags)\n",
    "all_tags.update(train2_model.tags)\n",
    "word_is_tag = set([word.upper() for word in train1_model.TagsPerWord if word.upper() in train1_model.TagsPerWord[word]])\n",
    "all_tags.difference_update(word_is_tag)\n",
    "print(all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_is_tag_u = set([word.upper() for word in train1_model.TagsPerWord if word.upper() in train1_model.TagsPerWord[word]])\n",
    "word_is_tag = set([word for word in train1_model.TagsPerWord if word.upper() in train1_model.TagsPerWord[word]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'#', '$', \"''\", ',', '-LRB-', '-RRB-', '.', ':', 'IN', 'TO', 'UH', '``'}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_is_tag_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "strange_words = [word for word in train1_model.TagsPerWord if len(word_is_tag.intersection(train1_model.TagsPerWord[word])) == 1 and len(train1_model.TagsPerWord[word]) == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". 4914 ['.']\n",
      "Among 14 ['IN']\n",
      "into 115 ['IN']\n",
      "`` 838 ['``']\n",
      ", 6044 [',']\n",
      "'' 813 [\"''\"]\n",
      "to 2809 ['TO']\n",
      "than 190 ['IN']\n",
      "$ 773 ['$']\n",
      "from 544 ['IN']\n",
      "-- 256 [':']\n",
      "-LRB- 148 ['-LRB-']\n",
      "-RRB- 148 ['-RRB-']\n",
      "for 1022 ['IN']\n",
      "between 80 ['IN']\n",
      "at 533 ['IN']\n",
      "under 75 ['IN']\n",
      ": 149 [':']\n",
      "against 54 ['IN']\n",
      "Despite 16 ['IN']\n",
      "until 35 ['IN']\n",
      "if 95 ['IN']\n",
      "Like 3 ['IN']\n",
      "among 37 ['IN']\n",
      "Because 19 ['IN']\n",
      "To 16 ['TO']\n",
      "Under 31 ['IN']\n",
      "By 17 ['IN']\n",
      "If 52 ['IN']\n",
      "-LCB- 30 ['-LRB-']\n",
      "-RCB- 30 ['-RRB-']\n",
      "For 56 ['IN']\n",
      "whereas 1 ['IN']\n",
      "; 133 [':']\n",
      "At 41 ['IN']\n",
      "beyond 7 ['IN']\n",
      "... 19 [':']\n",
      "throughout 9 ['IN']\n",
      "without 34 ['IN']\n",
      "onto 4 ['IN']\n",
      "toward 18 ['IN']\n",
      "Along 1 ['IN']\n",
      "across 4 ['IN']\n",
      "After 15 ['IN']\n",
      "C$ 13 ['$']\n",
      "US$ 15 ['$']\n",
      "despite 17 ['IN']\n",
      "during 48 ['IN']\n",
      "Although 15 ['IN']\n",
      "Before 5 ['IN']\n",
      "Besides 3 ['IN']\n",
      "On 22 ['IN']\n",
      "within 24 ['IN']\n",
      "During 9 ['IN']\n",
      "via 39 ['IN']\n",
      "A$ 1 ['$']\n",
      "While 31 ['IN']\n",
      "although 17 ['IN']\n",
      "Since 12 ['IN']\n",
      "amid 4 ['IN']\n",
      "From 2 ['IN']\n",
      "unless 5 ['IN']\n",
      "? 43 ['.']\n",
      "Of 5 ['IN']\n",
      "! 5 ['.']\n",
      "per 10 ['IN']\n",
      "Over 5 ['IN']\n",
      "besides 2 ['IN']\n",
      "Until 4 ['IN']\n",
      "inside 4 ['IN']\n",
      "except 7 ['IN']\n",
      "Well 2 ['UH']\n",
      "aboard 2 ['IN']\n",
      "Unlike 3 ['IN']\n",
      "Out 1 ['IN']\n",
      "albeit 1 ['IN']\n",
      "atop 1 ['IN']\n",
      "Behind 2 ['IN']\n",
      "unlike 3 ['IN']\n",
      "en 1 ['IN']\n",
      "na 2 ['TO']\n",
      "Without 2 ['IN']\n",
      "a\\/k\\/a 1 ['IN']\n",
      "` 8 ['``']\n",
      "beside 1 ['IN']\n",
      "- 8 [':']\n",
      "Unless 1 ['IN']\n",
      "Through 2 ['IN']\n",
      "# 7 ['#']\n",
      "OF 1 ['IN']\n",
      "uh 1 ['UH']\n",
      "UNDER 1 ['IN']\n",
      "becase 1 ['IN']\n",
      "Yeah 2 ['UH']\n",
      "Oh 1 ['UH']\n",
      "Wham 1 ['UH']\n",
      "Bam 1 ['UH']\n",
      "Within 1 ['IN']\n",
      "Aw 1 ['UH']\n",
      "heck 1 ['UH']\n",
      "HK$ 6 ['$']\n",
      "Against 1 ['IN']\n"
     ]
    }
   ],
   "source": [
    "for word in strange_words:\n",
    "    print(word, train1_model.WordCount[word], train1_model.TagsPerWord[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TO']\n",
      "2809\n",
      "['IN', 'RP', 'RB']\n",
      "1994\n",
      "['UH']\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(train1_model.TagsPerWord['to'])\n",
    "print(train1_model.WordCount['to'])\n",
    "\n",
    "print(train1_model.TagsPerWord['in'])\n",
    "print(train1_model.WordCount['in'])\n",
    "\n",
    "print(train1_model.TagsPerWord['uh'])\n",
    "print(train1_model.WordCount['uh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236\n"
     ]
    }
   ],
   "source": [
    "print(len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out 109 ['RP', 'RB', 'IN', 'NN']\n",
      "with 567 ['IN', 'RB']\n",
      "that 1130 ['WDT', 'IN', 'DT', 'RB']\n",
      "in 1994 ['IN', 'RP', 'RB']\n",
      ". 4914 ['.']\n",
      "Among 14 ['IN']\n",
      "of 2926 ['IN', 'RP']\n",
      "into 115 ['IN']\n",
      "down 76 ['RP', 'RB', 'JJ', 'IN']\n",
      "by 576 ['IN', 'RP']\n",
      "`` 838 ['``']\n",
      ", 6044 [',']\n",
      "'' 813 [\"''\"]\n",
      "to 2809 ['TO']\n",
      "than 190 ['IN']\n",
      "$ 773 ['$']\n",
      "from 544 ['IN']\n",
      "-- 256 [':']\n",
      "about 286 ['RB', 'IN', 'RP']\n",
      "-LRB- 148 ['-LRB-']\n",
      "-RRB- 148 ['-RRB-']\n",
      "for 1022 ['IN']\n",
      "between 80 ['IN']\n",
      "on 728 ['IN', 'RP', 'RB']\n",
      "after 107 ['IN', 'RB']\n",
      "at 533 ['IN']\n",
      "ago 60 ['RB', 'IN']\n",
      "under 75 ['IN']\n",
      "as 566 ['IN', 'RB']\n",
      "whether 42 ['IN', 'CC']\n",
      ": 149 [':']\n",
      "against 54 ['IN']\n",
      "Despite 16 ['IN']\n",
      "past 64 ['JJ', 'NN', 'IN']\n",
      "while 61 ['IN', 'NN']\n",
      "so 73 ['IN', 'RB']\n",
      "That 70 ['DT', 'WDT', 'IN']\n",
      "next 101 ['JJ', 'IN', 'RB']\n",
      "well 57 ['RB', 'UH', 'NN']\n",
      "until 35 ['IN']\n",
      "because 132 ['IN', 'RB']\n",
      "over 108 ['IN', 'RB', 'RP']\n",
      "before 71 ['RB', 'IN']\n",
      "no 106 ['DT', 'RB', 'UH']\n",
      "if 95 ['IN']\n",
      "through 86 ['IN', 'RB']\n",
      "but 197 ['CC', 'IN', 'RB']\n",
      "In 226 ['IN', 'NNP']\n",
      "Like 3 ['IN']\n",
      "among 37 ['IN']\n",
      "once 23 ['RB', 'IN']\n",
      "Because 19 ['IN']\n",
      "To 16 ['TO']\n",
      "Under 31 ['IN']\n",
      "off 63 ['RP', 'RB', 'IN']\n",
      "By 17 ['IN']\n",
      "though 25 ['IN', 'RB']\n",
      "If 52 ['IN']\n",
      "-LCB- 30 ['-LRB-']\n",
      "-RCB- 30 ['-RRB-']\n",
      "For 56 ['IN']\n",
      "whereas 1 ['IN']\n",
      "; 133 [':']\n",
      "since 68 ['IN', 'RB']\n",
      "At 41 ['IN']\n",
      "So 22 ['IN', 'RB']\n",
      "around 32 ['RB', 'IN', 'RP']\n",
      "above 28 ['RB', 'IN', 'JJ']\n",
      "' 86 ['POS', \"''\"]\n",
      "like 55 ['IN', 'VB', 'VBP']\n",
      "beyond 7 ['IN']\n",
      "... 19 [':']\n",
      "behind 12 ['IN', 'RP', 'RB']\n",
      "throughout 9 ['IN']\n",
      "without 34 ['IN']\n",
      "outside 18 ['JJ', 'IN', 'NN']\n",
      "up 225 ['IN', 'RP', 'RB']\n",
      "onto 4 ['IN']\n",
      "toward 18 ['IN']\n",
      "Along 1 ['IN']\n",
      "across 4 ['IN']\n",
      "de 20 ['IN', 'NNP', 'FW']\n",
      "After 15 ['IN']\n",
      "C$ 13 ['$']\n",
      "US$ 15 ['$']\n",
      "despite 17 ['IN']\n",
      "during 48 ['IN']\n",
      "Although 15 ['IN']\n",
      "Before 5 ['IN']\n",
      "Besides 3 ['IN']\n",
      "plus 5 ['CC', 'IN']\n",
      "On 22 ['IN']\n",
      "along 19 ['IN', 'RB', 'RP']\n",
      "within 24 ['IN']\n",
      "below 13 ['IN', 'RB']\n",
      "As 47 ['IN', 'RB']\n",
      "During 9 ['IN']\n",
      "C 3 ['NNP', '$']\n",
      "via 39 ['IN']\n",
      "A$ 1 ['$']\n",
      "While 31 ['IN']\n",
      "near 12 ['IN', 'JJ']\n",
      "although 17 ['IN']\n",
      "Since 12 ['IN']\n",
      "With 26 ['IN', 'NNP']\n",
      "About 5 ['RB', 'IN']\n",
      "amid 4 ['IN']\n",
      "fiscal 40 ['JJ', 'IN']\n",
      "From 2 ['IN']\n",
      "No 11 ['DT', 'UH']\n",
      "unless 5 ['IN']\n",
      "? 43 ['.']\n",
      "Of 5 ['IN']\n",
      "! 5 ['.']\n",
      "per 10 ['IN']\n",
      "Whether 2 ['IN', 'NNP']\n",
      "worth 9 ['JJ', 'IN', 'NN']\n",
      "Over 5 ['IN']\n",
      "besides 2 ['IN']\n",
      "Once 5 ['IN', 'RB']\n",
      "Though 13 ['IN', 'NNP']\n",
      "Until 4 ['IN']\n",
      "inside 4 ['IN']\n",
      "except 7 ['IN']\n",
      "Well 2 ['UH']\n",
      "aboard 2 ['IN']\n",
      "Unlike 3 ['IN']\n",
      "Out 1 ['IN']\n",
      "albeit 1 ['IN']\n",
      "atop 1 ['IN']\n",
      "Behind 2 ['IN']\n",
      "unlike 3 ['IN']\n",
      "en 1 ['IN']\n",
      "na 2 ['TO']\n",
      "Without 2 ['IN']\n",
      "a\\/k\\/a 1 ['IN']\n",
      "` 8 ['``']\n",
      "beside 1 ['IN']\n",
      "- 8 [':']\n",
      "Unless 1 ['IN']\n",
      "Through 2 ['IN']\n",
      "# 7 ['#']\n",
      "OF 1 ['IN']\n",
      "uh 1 ['UH']\n",
      "UNDER 1 ['IN']\n",
      "becase 1 ['IN']\n",
      "OK 3 ['JJ', 'UH']\n",
      "Yeah 2 ['UH']\n",
      "Oh 1 ['UH']\n",
      "Wham 1 ['UH']\n",
      "Bam 1 ['UH']\n",
      "Within 1 ['IN']\n",
      "Aw 1 ['UH']\n",
      "heck 1 ['UH']\n",
      "HK$ 6 ['$']\n",
      "Against 1 ['IN']\n"
     ]
    }
   ],
   "source": [
    "features = []\n",
    "\n",
    "# one-to-one features\n",
    "for word in strange_words:\n",
    "    for tag in train1_model.TagsPerWord[word]:\n",
    "        features.append(Feature(f'w[i] == \"{word}\"', t=tag))\n",
    "    print(word, train1_model.WordCount[word], train1_model.TagsPerWord[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "unique = Counter(train1_model.unseparated).keys() # equals to list(set(words))\n",
    "counts = Counter(train1_model.unseparated).values() # counts the elements' frequency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_count = dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.Series(values_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ",_,                  6044\n",
       "the_DT               5320\n",
       "._.                  4914\n",
       "of_IN                2925\n",
       "to_TO                2809\n",
       "                     ... \n",
       "133_CD                  1\n",
       "attributable_JJ         1\n",
       "500-stock_JJ            1\n",
       "discrepancies_NNS       1\n",
       "728.5_CD                1\n",
       "Length: 15415, dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15415\n"
     ]
    }
   ],
   "source": [
    "print(len(set(train1_model.unseparated)))\n",
    "# print(train1_model.tag_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature:\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.equality_inds = kwargs\n",
    "        self.rules = args\n",
    "\n",
    "    def __call__(self, t2, t1, w, i, t, assertions=False):\n",
    "        if assertions:\n",
    "            assert isinstance(t2, str)\n",
    "            assert isinstance(t1, str)\n",
    "            assert isinstance(w, (tuple, list))\n",
    "            assert isinstance(i, int)\n",
    "            assert isinstance(t, str)\n",
    "        \n",
    "        def prefix(word, pre):\n",
    "            return word[:len(pre)] == pre\n",
    "        \n",
    "        def suffix(word, suf):\n",
    "            return word[len(suf)-1:] == suf\n",
    "        \n",
    "        def substr(word, sub):\n",
    "            return sub in word\n",
    "        \n",
    "        # check for equalities\n",
    "        for arg in ['t2', 't1', 'i', 't']:\n",
    "            if arg in self.equality_inds and eval(arg) != self.equality_inds[arg]:\n",
    "                return False\n",
    "        \n",
    "        for rule in self.rules:\n",
    "            if not eval(rule):\n",
    "                return False\n",
    "        return True\n",
    "        \n",
    "    def __str__(self):\n",
    "        return str(self.equality_inds) + str(self.rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_generator():\n",
    "    features = []\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = Feature('w[i] == \"abc\"', 'prefix(w[i-1], \"pre\")', 'suffix(w[i+1], \"ing\")', t2='VB', t='BB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = 'VB'\n",
    "t1 = 'NN'\n",
    "w = ('preprocess', 'abc', 'being')\n",
    "i = 1\n",
    "t = 'BB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(feat(t2, t1, w, i, t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureGenerator:\n",
    "    def __init__(self, dataset):\n",
    "        self.lines_list_of_word_lists = dataset\n",
    "        self.words_set = set()\n",
    "        self.tags_set = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/c/Users/alexz/OneDrive/MainEnv/nlp/HW1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The_DT Treasury_NNP is_VBZ still_RB working_VBG out_RP the_DT details_NNS with_IN bank_NN trade_NN associations_NNS and_CC the_DT other_JJ government_NN agencies_NNS that_WDT have_VBP a_DT hand_NN in_IN fighting_VBG money_NN laundering_NN ._.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(train1_path, 'r') as f:\n",
    "    for line in f:\n",
    "        print(line)\n",
    "        break\n",
    "#     text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The_DT Treasury_NNP is_VBZ still_RB working_VBG out_RP the_DT details_NNS with_IN bank_NN trade_NN associations_NNS and_CC the_DT other_JJ government_NN agencies_NNS that_WDT have_VBP a_DT hand_NN in_IN fighting_VBG money_NN laundering_NN ._.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filepath = 'train1.wtag'\n",
    "temp = open(train1_path, 'r')\n",
    "for line in temp:\n",
    "    print(line)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_line = lines[0].split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'DT']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_line[0].split('_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'Iliad.txt'\n",
    "with open(filepath) as fp:\n",
    "   line = fp.readline()\n",
    "   cnt = 1\n",
    "   while line:\n",
    "       print(\"Line {}: {}\".format(cnt, line.strip()))\n",
    "       line = fp.readline()\n",
    "       cnt += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_hw1",
   "language": "python",
   "name": "nlp_hw1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
