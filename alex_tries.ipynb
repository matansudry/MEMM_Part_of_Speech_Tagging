{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import preprocess, score, features, classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp1_path = 'data/comp1.words'\n",
    "comp2_path = 'data/comp2.words'\n",
    "test1_path = 'data/test1.wtag'\n",
    "train1_path = 'data/train1.wtag'\n",
    "train2_path = 'data/train2.wtag'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create FeatureGroup params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_thresholds = {\n",
    "    lambda t2, t1, w, i, t: tuple([t2, t1, t]):                               1,\n",
    "    lambda t2, t1, w, i, t: tuple([t1, t]):                                   1,\n",
    "    lambda t2, t1, w, i, t: tuple([w[i].lower(), t]):                         None,\n",
    "#     lambda t2, t1, w, i, t: tuple([w[i-1].lower(), t]):                       5,\n",
    "#     lambda t2, t1, w, i, t: tuple([w[i+1].lower(), t]):                       5,\n",
    "    lambda t2, t1, w, i, t: tuple([w[i][:3].lower(), t]):                     5,\n",
    "    lambda t2, t1, w, i, t: tuple([w[i][:2].lower(), t]):                     5,\n",
    "#     lambda t2, t1, w, i, t: tuple([w[i+1][:3].lower(), t]):                   5,\n",
    "#     lambda t2, t1, w, i, t: tuple([w[i-1][:3].lower(), t]):                   5,\n",
    "    lambda t2, t1, w, i, t: tuple([w[i][-3:].lower(), t]):                    5,\n",
    "    lambda t2, t1, w, i, t: tuple([w[i][-2:].lower(), t]):                    5,\n",
    "#     lambda t2, t1, w, i, t: tuple([w[i+1][-3:].lower(), t]):                  5,\n",
    "#     lambda t2, t1, w, i, t: tuple([w[i-1][-3:].lower(), t]):                  5,\n",
    "    lambda t2, t1, w, i, t: tuple([w[i].isalnum(), t]):                       1,\n",
    "    lambda t2, t1, w, i, t: tuple([w[i].isalpha(), t]):                       1,\n",
    "    lambda t2, t1, w, i, t: tuple([w[i].isascii(), t]):                       1,\n",
    "    lambda t2, t1, w, i, t: tuple([w[i].isdecimal(), t]):                     1,\n",
    "    lambda t2, t1, w, i, t: tuple([w[i].isdigit(), t]):                       1,\n",
    "    lambda t2, t1, w, i, t: tuple([w[i].islower(), t]):                       1,\n",
    "    lambda t2, t1, w, i, t: tuple([w[i].isnumeric(), t]):                     1,\n",
    "    lambda t2, t1, w, i, t: tuple([w[i].istitle(), t]):                       1,\n",
    "    lambda t2, t1, w, i, t: tuple([w[i].isupper(), t]):                       1,\n",
    "    lambda t2, t1, w, i, t: tuple([len(w[i]) == 1, t]):                       1,\n",
    "    lambda t2, t1, w, i, t: tuple([len(w[i]) == 2, t]):                       1,\n",
    "    lambda t2, t1, w, i, t: tuple([len(w[i]) == 3, t]):                       1,\n",
    "    lambda t2, t1, w, i, t: tuple([w[i][0].islower(), t]):                    1,\n",
    "    lambda t2, t1, w, i, t: tuple([any(char.isdigit() for char in w[i]), t]): 1,\n",
    "    lambda t2, t1, w, i, t: tuple([any(char.isupper() for char in w[i]), t]): 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.67 s, sys: 46.9 ms, total: 1.72 s\n",
      "Wall time: 1.71 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_dataset = preprocess.Dataset(train1_path)\n",
    "val_dataset = preprocess.Dataset(test1_path)\n",
    "feature_vector = features.create_feature_vector(train_dataset,\n",
    "                                                group_thresholds=group_thresholds,\n",
    "                                                pruning=True,\n",
    "                                                get_stats=False,\n",
    "                                                assertions=True,\n",
    "                                                calls_counter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0 = np.random.rand(len(feature_vector)).astype(np.float32)/20\n",
    "seed = 42\n",
    "models_path = 'models'\n",
    "version = 1\n",
    "save = True\n",
    "\n",
    "model = classifier.Model(version=version,\n",
    "                         w0=w0,\n",
    "                         tags=train_dataset.tags,\n",
    "                         feature_vector=feature_vector,\n",
    "                         seed=seed,\n",
    "                         score_func=score.accuracy,\n",
    "                         models_path=models_path,\n",
    "                         save=save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   1/20 | train_loss 232022.011453 | val_loss 121288.541844 | train_score 0.021763 | val_score 0.0229 | train_time   0.73 min\n",
      "epoch   2/20 | train_loss 146758.931201 | val_loss 77023.877246 | train_score 0.022887 | val_score 0.0210 | train_time   1.51 min\n",
      "epoch   3/20 | train_loss 90.147963 | val_loss 87.094723 | train_score 0.022296 | val_score 0.0228 | train_time   2.30 min\n",
      "epoch   4/20 | train_loss 91.262248 | val_loss 87.713709 | train_score 0.023060 | val_score 0.0210 | train_time   3.07 min\n",
      "epoch   5/20 | train_loss 89.227516 | val_loss 87.094878 | train_score 0.022690 | val_score 0.0216 | train_time   3.81 min\n",
      "epoch   6/20 | train_loss 90.369326 | val_loss 87.094878 | train_score 0.023207 | val_score 0.0217 | train_time   4.57 min\n",
      "epoch   7/20 | train_loss 89.565198 | val_loss 87.094878 | train_score 0.022559 | val_score 0.0233 | train_time   5.34 min\n",
      "epoch   8/20 | train_loss 90.881539 | val_loss 87.173560 | train_score 0.021976 | val_score 0.0218 | train_time   6.08 min\n",
      "epoch   9/20 | train_loss 89.945740 | val_loss 87.094880 | train_score 0.022977 | val_score 0.0235 | train_time   6.83 min\n",
      "epoch  10/20 | train_loss 69.957830 | val_loss 87.094878 | train_score 0.022247 | val_score 0.0225 | train_time   7.52 min\n",
      "epoch  11/20 | train_loss 88.809371 | val_loss 87.094878 | train_score 0.022542 | val_score 0.0242 | train_time   8.28 min\n",
      "epoch  12/20 | train_loss 90.002831 | val_loss 87.094878 | train_score 0.022854 | val_score 0.0219 | train_time   9.05 min\n"
     ]
    }
   ],
   "source": [
    "weight_decay = 1e7\n",
    "batch_size = 512\n",
    "epochs = 20\n",
    "tqdm_bar = False\n",
    "\n",
    "v_min, f_min, d_min = model.train(epochs=epochs,\n",
    "                                  train_dataset=train_dataset,\n",
    "                                  val_dataset=val_dataset,\n",
    "                                  batch_size=batch_size,\n",
    "                                  weight_decay=weight_decay,\n",
    "                                  iprint=-1,\n",
    "                                  save=True,\n",
    "                                  tqdm_bar=tqdm_bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model version: 2\n",
      "epochs: 2\n",
      "train_time: 1.522\n",
      "\n",
      "last train_loss: 149423.090295\n",
      "last val_loss: 78273.272377\n",
      "last train_score: 0.022485\n",
      "last val_score: 0.021627\n",
      "best val_accuracy: 0.0216 at epoch 1\n"
     ]
    }
   ],
   "source": [
    "model = classifier.load_model(version, models_path, epoch=-1, seed=42, prints=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.00650830e-05,  5.20087830e-07,  5.03616629e-08, ...,\n",
       "       -1.35678368e-10, -2.23178660e-11, -1.39021980e-10])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00295728559167523"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(v_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36385.19124304004"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(f_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'grad': array([ 36.0791321 , 189.732937  , 181.03639973, ..., 191.54076316,\n",
       "         62.58931548,  56.02766903]),\n",
       " 'task': b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT',\n",
       " 'funcalls': 6,\n",
       " 'nit': 1,\n",
       " 'warnflag': 1}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(d_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_group: FeatureGroup(tuple([t2, t1, t])) | feats: 5192\n",
      "feat_group: FeatureGroup(tuple([t1, t])) | feats: 908\n",
      "feat_group: FeatureGroup(tuple([w[i].lower(), t])) | feats: 14719\n",
      "feat_group: FeatureGroup(tuple([w[i][:3].lower(), t])) | feats: 2431\n",
      "feat_group: FeatureGroup(tuple([w[i][:2].lower(), t])) | feats: 1432\n",
      "feat_group: FeatureGroup(tuple([w[i][-3:].lower(), t])) | feats: 1757\n",
      "feat_group: FeatureGroup(tuple([w[i][-2:].lower(), t])) | feats: 955\n",
      "feat_group: FeatureGroup(tuple([w[i].isalnum(), t])) | feats: 60\n",
      "feat_group: FeatureGroup(tuple([w[i].isalpha(), t])) | feats: 60\n",
      "feat_group: FeatureGroup(tuple([w[i].isascii(), t])) | feats: 44\n",
      "feat_group: FeatureGroup(tuple([w[i].isdecimal(), t])) | feats: 45\n",
      "feat_group: FeatureGroup(tuple([w[i].isdigit(), t])) | feats: 45\n",
      "feat_group: FeatureGroup(tuple([w[i].islower(), t])) | feats: 75\n",
      "feat_group: FeatureGroup(tuple([w[i].isnumeric(), t])) | feats: 45\n",
      "feat_group: FeatureGroup(tuple([w[i].istitle(), t])) | feats: 76\n",
      "feat_group: FeatureGroup(tuple([w[i].isupper(), t])) | feats: 56\n",
      "feat_group: FeatureGroup(tuple([len(w[i]) == 1, t])) | feats: 56\n",
      "feat_group: FeatureGroup(tuple([len(w[i]) == 2, t])) | feats: 66\n",
      "feat_group: FeatureGroup(tuple([len(w[i]) == 3, t])) | feats: 69\n",
      "feat_group: FeatureGroup(tuple([w[i][0].islower(), t])) | feats: 74\n",
      "feat_group: FeatureGroup(tuple([any(char.isdigit() for char in w[i]), t])) | feats: 49\n",
      "feat_group: FeatureGroup(tuple([any(char.isupper() for char in w[i]), t])) | feats: 75\n",
      "feat_groups: 22 | total_feats: 28289\n"
     ]
    }
   ],
   "source": [
    "for feat in feature_vector.feats:\n",
    "    print('feat_group:', feat, '| feats:', len(feat))\n",
    "print('feat_groups:', len(feature_vector.feats), '| total_feats:', len(feature_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test run train_dataset\n",
    "# tic = time.time()\n",
    "# for t2, t1, w, i, t in train_dataset:\n",
    "#     feat_vec_t = feature_vector(t2, t1, w, i, t, fmt='vec')\n",
    "# print('fmt=vec: {:.3f} sec'.format(time.time() - tic))\n",
    "\n",
    "# tic = time.time()\n",
    "# for t2, t1, w, i, t in train_dataset:\n",
    "#     feat_list_t = feature_vector(t2, t1, w, i, t, fmt='list')\n",
    "# print('fmt=list: {:.3f} sec'.format(time.time() - tic))\n",
    "\n",
    "# tic = time.time()\n",
    "# for t2, t1, w, i, t in train_dataset:\n",
    "#     feat_vec_t, feat_list_t = feature_vector(t2, t1, w, i, t, fmt='both')\n",
    "# print('fmt=vec+list: {:.3f} sec'.format(time.time() - tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tag in train1_statistics.words_per_tag:\n",
    "#     if len(train1_statistics.words_per_tag[tag]) < 10:\n",
    "#         print('{:5} tf: {:5d} unique_count: {:4d} words: {}'.format(tag, train1_statistics.tags_count[tag], len(train1_statistics.words_per_tag[tag]),\n",
    "#                                                                     train1_statistics.words_per_tag[tag]))\n",
    "#     else:\n",
    "#         print('{:5} tf: {:5d} unique_count: {:4d}'.format(tag, train1_statistics.tags_count[tag], len(train1_statistics.words_per_tag[tag])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = []\n",
    "\n",
    "# # one-to-one features\n",
    "# for word in strange_words:\n",
    "#     features.append(Feature(f'w[i] == \"{word}\"', t=train1_model.tags_per_word[word][0]))\n",
    "#     print(word, train1_model.WordCount[word], train1_model.TagsPerWord[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_hw1",
   "language": "python",
   "name": "nlp_hw1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
